{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install pytorch_tabnet\n",
        "%pip install catboost\n",
        "%pip install https://github.com/schufa-innovationlab/model-trees/archive/master.zip"
      ],
      "metadata": {
        "id": "tC7VxriKcLvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa118a1e-25e6-45b6-fd46-c268488f6c61"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_tabnet\n",
            "  Downloading pytorch_tabnet-4.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.22.4)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.10.1)\n",
            "Collecting torch<2.0,>=1.2 (from pytorch_tabnet)\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (4.65.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.0,>=1.2->pytorch_tabnet) (4.5.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<2.0,>=1.2->pytorch_tabnet)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<2.0,>=1.2->pytorch_tabnet)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<2.0,>=1.2->pytorch_tabnet)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<2.0,>=1.2->pytorch_tabnet)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0,>=1.2->pytorch_tabnet) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0,>=1.2->pytorch_tabnet) (0.40.0)\n",
            "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, pytorch_tabnet\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pytorch_tabnet-4.0 torch-1.13.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://github.com/schufa-innovationlab/model-trees/archive/master.zip\n",
            "  Downloading https://github.com/schufa-innovationlab/model-trees/archive/master.zip\n",
            "\u001b[2K     \u001b[32m\\\u001b[0m \u001b[32m30.7 kB\u001b[0m \u001b[31m183.8 kB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from modeltrees==0.1.1) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from modeltrees==0.1.1) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->modeltrees==0.1.1) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->modeltrees==0.1.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->modeltrees==0.1.1) (3.1.0)\n",
            "Building wheels for collected packages: modeltrees\n",
            "  Building wheel for modeltrees (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for modeltrees: filename=modeltrees-0.1.1-py3-none-any.whl size=19094 sha256=dcc572fbaa50c0afda486bc98650d0d6228d7df06bb9ef68747814743321a4a5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7a9960w4/wheels/47/ce/e9/863111507f35cb26b7c638d74f38e5d8b4b424d6913d15370b\n",
            "Successfully built modeltrees\n",
            "Installing collected packages: modeltrees\n",
            "Successfully installed modeltrees-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "from keras.regularizers import l1, l2, l1_l2\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor"
      ],
      "metadata": {
        "id": "132YYDBEcS9Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qp--yT6loO8p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.stats.api as sms\n",
        "from statsmodels.compat import lzip\n",
        "from statsmodels.stats.outliers_influence import OLSInfluence\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import lightgbm as lgb\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from catboost import CatBoostClassifier, CatBoostRegressor\n",
        "from modeltrees import ModelTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/MyDrive/244"
      ],
      "metadata": {
        "id": "Jqa2Gb3MpJiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d97da9b-0ed3-4e13-da6f-ddcfa0612836"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hardy_cv(name, model, dataset, cv=5):  # We'll train only\n",
        "  cv_scores = cross_val_score(\n",
        "      model, X_train, Y_train, cv=cv, scoring='accuracy')\n",
        "  print('accuracy = ', cv_scores.mean())\n",
        "  return { 'mean': cv_scores.mean(), 'scores': cv_scores }\n",
        "\n",
        "def hardy_train_with_validation(name, model, dataset):  # We'll train only\n",
        "  X_train = dataset['X_train']\n",
        "  Y_train = dataset['Y_train']\n",
        "\n",
        "  X_train_train, X_train_val, Y_train_train, Y_train_val = train_test_split(\n",
        "    X_train, Y_train, test_size=0.2, random_state=100)\n",
        "  eval_set = [(X_train_val, Y_train_val)]\n",
        "  model.fit(X_train_train, Y_train_train,\n",
        "            eval_set = eval_set, metrics='accuracy',\n",
        "            verbose=False, early_stopping_rounds=10)\n",
        "\n",
        "def hardy_train(name, model, dataset):  # We'll train only\n",
        "  X_train = dataset['X_train']\n",
        "  Y_train = dataset['Y_train']\n",
        "  model.fit(X_train, Y_train)\n",
        "\n",
        "def hardy_predict(name, model, dataset):  # we'll predict only\n",
        "  global all_results\n",
        "  X_train = dataset['X_train']\n",
        "  Y_train = dataset['Y_train']\n",
        "  X_test = dataset['X_test']\n",
        "  Y_test = dataset['Y_test']\n",
        "  Y_train_pred = model.predict(X_train)\n",
        "  Y_test_pred = model.predict(X_test)\n",
        "  if name == 'Model Tree' or name == \"Gaussian Process\":\n",
        "    Y_test_proba = None\n",
        "  else:\n",
        "    Y_test_proba = model.predict_proba(X_test)\n",
        "\n",
        "  metrics = hardy_evaluate(name + \" (train)\", Y_train, Y_train_pred)\n",
        "  metrics = hardy_evaluate(name, Y_test, Y_test_pred)\n",
        "  # hardy_roc_auc(name, Y_test, Y_test_proba)\n",
        "  results = { 'metrics': metrics, 'pred': Y_test_pred, 'proba': Y_test_proba }\n",
        "  all_results[name] = results # posting the result to all_results{}\n",
        "  return results\n",
        "\n",
        "def hardy_predict_nn(name, model, dataset):  # we'll predict only\n",
        "  global all_results  \n",
        "  X_test = dataset['X_test']\n",
        "  Y_test = dataset['Y_test']\n",
        "  Y_proba = model.predict(X_test)\n",
        "  Y_pred = np.argmax(Y_proba, axis=1)\n",
        "  metrics = hardy_evaluate(name, Y_test, Y_pred)\n",
        "  results = { 'metrics': metrics, 'pred': Y_pred, 'proba': Y_proba }\n",
        "  all_results[name] = results # posting the result to all_results{}\n",
        "  return results\n",
        "\n",
        "def hardy_train_predict(name, model, dataset):  # train and predict\n",
        "  hardy_train(name, model, dataset)\n",
        "  return hardy_predict(name, model, dataset)\n",
        "\n",
        "def hardy_roc_auc(name, Y_test, Y_test_proba):\n",
        "  Y_test_proba_1d = [v[1] for v in Y_test_proba]\n",
        "  roc_auc = roc_auc_score(Y_test, Y_test_proba_1d)\n",
        "  fpr, tpr, thresholds = roc_curve(Y_test, Y_test_proba_1d)\n",
        "  plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
        "  plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line representing random guessing\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('Receiver Operating Characteristic')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.show()\n",
        "\n",
        "def hardy_evaluate(name, Y_test, Y_pred):  # evaluate only\n",
        "  accuracy = accuracy_score(Y_test, Y_pred)\n",
        "  precision = precision_score(Y_test, Y_pred)\n",
        "  recall = recall_score(Y_test, Y_pred)\n",
        "  f1 = f1_score(Y_test, Y_pred)\n",
        "  print(f'\"{name}\": accuracy = {accuracy}')\n",
        "  print(f'\"{name}\": precision = {precision}')\n",
        "  print(f'\"{name}\": recall = {recall}')\n",
        "  print(f'\"{name}\": f1 = {f1}')\n",
        "  cm = confusion_matrix(Y_test, Y_pred)\n",
        "  print('-------------------------------------')\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print('-------------------------------------')\n",
        "  print('               L      W (predicted)')\n",
        "  for i in range(2):  # binary\n",
        "    row_str = \"    \".join([str(count) for count in cm[i]])\n",
        "    truth = 'L (truth)' if i == 0 else 'W (truth)'\n",
        "    print(f\"  {truth}: {row_str}\")\n",
        "  print('-------------------------------------')\n",
        "  return {\n",
        "      'accuracy': accuracy,\n",
        "      'precision': precision,\n",
        "      'recall': recall,\n",
        "      'f1': f1,\n",
        "  }\n",
        "\n",
        "def hardy_experiment(name, model, dataset):\n",
        "  print('Experiment: train and predict ...')\n",
        "  hardy_train_predict(name, model, dataset)\n",
        "  \n",
        "def hardy_pca(dataset, N=20):\n",
        "  pca = PCA(n_components=N)\n",
        "\n",
        "  X_train_pca = pd.DataFrame(pca.fit_transform(dataset['X_train']))\n",
        "  X_test_pca = pd.DataFrame(pca.transform(dataset['X_test']))\n",
        "  return {\n",
        "      'X_train': X_train_pca,\n",
        "      'Y_train': dataset['Y_train'],\n",
        "      'X_test': X_test_pca,\n",
        "      'Y_test': dataset['Y_test'],\n",
        "  }"
      ],
      "metadata": {
        "id": "hq9BWrXj0QFo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_lr():\n",
        "  lr_model = LogisticRegression()\n",
        "  hardy_experiment(\"Linear Regression\", lr_model, dataset)\n",
        "\n",
        "def run_xgb():\n",
        "  xgb_model = xgb.XGBClassifier(objective= 'binary:logistic')\n",
        "  hardy_experiment('XGBoost', xgb_model, dataset)\n",
        "\n",
        "def run_lgb():\n",
        "  lgb_model = lgb.LGBMClassifier()\n",
        "  hardy_experiment(\"LightGBM\", lgb_model, dataset)\n",
        "\n",
        "def run_knn():  # crash\n",
        "  knn_model = KNeighborsClassifier()  # n_neighbors=5\n",
        "  hardy_experiment(\"KNN\", knn_model, dataset)\n",
        "\n",
        "def run_gaussian_process():\n",
        "  gp_kernel = RBF(length_scale=1.0)\n",
        "  gp_model = GaussianProcessClassifier(kernel=gp_kernel)\n",
        "  hardy_experiment(\"Gaussian Process\", gp_model, dataset)\n",
        "\n",
        "def run_svn():\n",
        "  svc_model = SVC(kernel='rbf', probability=True)\n",
        "  hardy_experiment(\"SVM Classifier\", svc_model, dataset)\n",
        "\n",
        "def run_naive_bayes():\n",
        "  naivebayes_model = GaussianNB() # don't do grid-search\n",
        "  hardy_experiment('Naive Bayes', naivebayes_model, dataset)\n",
        "\n",
        "def run_decision_tree():\n",
        "  decision_tree_model = DecisionTreeClassifier()\n",
        "  hardy_experiment(\"Decision Tree\", decision_tree_model, dataset)\n",
        "  \n",
        "def run_adaboost():\n",
        "  adaboost_model = AdaBoostClassifier()\n",
        "  hardy_experiment(\"AdaBoost\", adaboost_model, dataset)\n",
        "\n",
        "def run_random_forest():\n",
        "  random_forest_model = RandomForestClassifier()\n",
        "  hardy_experiment(\"Random Forest\", random_forest_model, dataset)\n",
        "  \n",
        "def run_qda():\n",
        "  qda_model = QuadraticDiscriminantAnalysis()\n",
        "  hardy_experiment(\"Quadratic Discriminant Analysis\",\n",
        "                                 qda_model, dataset)\n",
        "  \n",
        "def run_catboost():\n",
        "  catboost_model = CatBoostClassifier(logging_level='silent')\n",
        "  hardy_experiment(\"CatBoost\", catboost_model, dataset)\n",
        "\n",
        "def run_model_tree():\n",
        "  dataset_numpy = {\n",
        "      'X_train': dataset['X_train'].to_numpy(),\n",
        "      'Y_train': dataset['Y_train'].to_numpy(),\n",
        "      'X_test': dataset['X_test'].to_numpy(),\n",
        "      'Y_test': dataset['Y_test'].to_numpy(),\n",
        "  }\n",
        "  mt_model = ModelTreeClassifier()\n",
        "  hardy_experiment(\"Model Tree\", mt_model, dataset_numpy)\n",
        "\n",
        "def run_ensemble(names, algo=None):\n",
        "  if algo == None:\n",
        "    run_ensemble(names, 'add')\n",
        "    run_ensemble(names, 'mult')\n",
        "    run_ensemble(names, 'vote')\n",
        "    return\n",
        "  \n",
        "  assert(algo == 'add' or algo == 'mult' or algo == 'vote')\n",
        "  predictions = [all_results[name]['proba'] for name in names]\n",
        "  Y_test = dataset['Y_test']\n",
        "  Y_pred = [1] * len(Y_test)\n",
        "  for i in range(len(Y_test)):\n",
        "    prob_L = 0\n",
        "    prob_W = 0\n",
        "    for p in predictions:\n",
        "      if algo == 'add':\n",
        "        prob_L += p[i][0]\n",
        "        prob_W += p[i][1]\n",
        "      elif algo == 'mult':  # mult = add in log-scale\n",
        "        prob_L += math.log(p[i][0] + 1e-9)\n",
        "        prob_W += math.log(p[i][1] + 1e-9)\n",
        "      elif algo == 'vote':\n",
        "        prob_L += p[i][0] >= 0.5\n",
        "        prob_W += p[i][1] >= 0.5\n",
        "      else:\n",
        "        assert(False)\n",
        "    Y_pred[i] = 1 if prob_W >= prob_L else 0\n",
        "  metrics = hardy_evaluate(f'Ensemble/{algo}', Y_test, Y_pred)\n",
        "  all_results[f'Ensemble/{algo}'] = {\n",
        "    'metrics': metrics\n",
        "  }\n",
        "\n",
        "def run_elo(feature='last'):\n",
        "  if GLOBAL_PCA:\n",
        "    return # cannot run this when we have done PCA\n",
        "\n",
        "  Y_test = dataset['Y_test']\n",
        "  Y_pred = []\n",
        "  for i, r in X_test.iterrows():\n",
        "    Y_pred.append(\n",
        "        1 if r[f'elo-home-{feature}'] >= r[f'elo-away-{feature}'] else 0)\n",
        "  metrics = hardy_evaluate(f'Elo ({feature})', Y_test, Y_pred)\n",
        "  all_results[f'Elo ({feature})'] = {\n",
        "    'metrics': metrics\n",
        "  }\n"
      ],
      "metadata": {
        "id": "RCa6s7M0enOX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_nn():\n",
        "\n",
        "  X_train = dataset['X_train']\n",
        "  Y_train = dataset['Y_train']\n",
        "  X_train_train, X_train_val, Y_train_train, Y_train_val = train_test_split(\n",
        "    X_train, Y_train, test_size=0.2, random_state=100)\n",
        "\n",
        "  label_encoder = LabelEncoder()\n",
        "  Y_train_train_encoded = label_encoder.fit_transform(Y_train_train)\n",
        "  Y_train_val_encoded = label_encoder.fit_transform(Y_train_val)\n",
        "\n",
        "  # Convert to one-hot encoded vectors\n",
        "  Y_train_train_one_hot = np_utils.to_categorical(Y_train_train_encoded)\n",
        "  Y_train_val_one_hot = np_utils.to_categorical(Y_train_val_encoded)\n",
        "\n",
        "  #########################################################################\n",
        "\n",
        "  l2_value = 0.01\n",
        "  nn_model = Sequential()\n",
        "  nn_model.add(Dense(100, input_dim=X_train_train.shape[1], activation='relu',\n",
        "                    kernel_regularizer=l2(l2_value)))\n",
        "  nn_model.add(Dropout(.2))\n",
        "  nn_model.add(Dense(100, activation='relu',\n",
        "              kernel_regularizer=l2(l2_value)))\n",
        "  nn_model.add(Dropout(.2))\n",
        "  nn_model.add(Dense(100, activation='relu',\n",
        "              kernel_regularizer=l2(l2_value)))\n",
        "  nn_model.add(Dropout(.2))\n",
        "  nn_model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "  #########################################################################\n",
        "\n",
        "  optimizer = Adam(learning_rate=0.001)\n",
        "  nn_model.compile(\n",
        "      loss='categorical_crossentropy',\n",
        "      optimizer=optimizer, metrics=['accuracy'])\n",
        "  nn_model.fit(X_train_train, Y_train_train_one_hot,\n",
        "              validation_data=(X_train_val, Y_train_val_one_hot),\n",
        "              epochs=15, batch_size=32)\n",
        "  \n",
        "  nn_result = hardy_predict_nn('Neural Network', nn_model, dataset)"
      ],
      "metadata": {
        "id": "MAgh1aXM5X-7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_tabnet():\n",
        "  global all_results\n",
        "  X_train = dataset['X_train']\n",
        "  Y_train = dataset['Y_train']\n",
        "  X_test = dataset['X_test']\n",
        "  Y_test = dataset['Y_test']\n",
        "  X_train_train, X_train_val, Y_train_train, Y_train_val = train_test_split(\n",
        "    X_train, Y_train, test_size=0.2, random_state=100)\n",
        "\n",
        "  X_train_train = X_train_train.to_numpy()\n",
        "  X_train_val = X_train_val.to_numpy()\n",
        "  Y_train_train = Y_train_train.to_numpy().squeeze()\n",
        "  Y_train_val = Y_train_val.to_numpy().squeeze()\n",
        "\n",
        "  print(X_train_train.shape)\n",
        "  print(X_train_val.shape)\n",
        "  print(Y_train_train.shape)\n",
        "  print(Y_train_val.shape)\n",
        "\n",
        "  tabnet_model = TabNetClassifier()\n",
        "  tabnet_model.fit(\n",
        "    X_train_train, Y_train_train,\n",
        "    eval_set=[(X_train_train, Y_train_train), (X_train_val, Y_train_val)],\n",
        "    max_epochs=100, patience=10)\n",
        "  \n",
        "  X_test = dataset['X_test']\n",
        "  Y_test = dataset['Y_test']\n",
        "  X_test = X_test.to_numpy()\n",
        "  Y_test = Y_test.to_numpy().squeeze()\n",
        "\n",
        "  Y_pred = tabnet_model.predict(X_test)\n",
        "  Y_proba = tabnet_model.predict_proba(X_test)\n",
        "  metrics = hardy_evaluate('TabNet', dataset['Y_test'], Y_pred)\n",
        "\n",
        "  results = {\n",
        "    'metrics': metrics,\n",
        "    'pred': Y_pred,\n",
        "    'proba': Y_proba }\n",
        "  all_results['TabNet'] = results # posting the result to all_results{}\n",
        "  return results"
      ],
      "metadata": {
        "id": "h6WPvn9TiTpX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Specification"
      ],
      "metadata": {
        "id": "jbU0QyFXH_Mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TABULAR_CSV = './tabular-100-100-original.csv'\n",
        "GLOBAL_PCA = False"
      ],
      "metadata": {
        "id": "DmMS0qTiH5wx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabular = pd.read_csv(TABULAR_CSV)\n",
        "  # see report for which one to use"
      ],
      "metadata": {
        "id": "po22OA-xo8Rk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabular = tabular.drop(['Unnamed: 0'], axis=1)\n",
        "XY_train = tabular[tabular['date'] < '2019-06-30']\n",
        "XY_test = tabular[tabular['date'] >= '2019-06-30']\n",
        "XY_train = shuffle(XY_train, random_state=42)\n",
        "\n",
        "print(f'train = {XY_train.shape}')\n",
        "print(f'test = {XY_test.shape}')\n",
        "\n",
        "X_train = XY_train.drop(['date', 'home', 'away', 'rivalry', 'label'], axis=1)\n",
        "Y_train = XY_train['label']\n",
        "X_test = XY_test.drop(['date', 'home', 'away', 'rivalry', 'label'], axis=1)\n",
        "Y_test = XY_test['label']\n",
        "print(f'X_train: {X_train.columns}')\n",
        "dataset = {\n",
        "    'X_train': X_train,\n",
        "    'Y_train': Y_train,\n",
        "    'X_test': X_test,\n",
        "    'Y_test': Y_test,    \n",
        "}\n",
        "if GLOBAL_PCA:\n",
        "  print('performing PCA ...')\n",
        "  dataset = hardy_pca(dataset)\n",
        "  X_train = dataset['X_train']\n",
        "  Y_train = dataset['Y_train']\n",
        "  X_test = dataset['X_test']\n",
        "  Y_test = dataset['Y_test']\n",
        "\n",
        "all_results = {}"
      ],
      "metadata": {
        "id": "Z-_e5G5wgVrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b3a2d2-c167-4bf5-b174-489d807f9e27"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train = (3468, 203)\n",
            "test = (1105, 203)\n",
            "X_train: Index(['passing-yard-ratio-home-last', 'fourth-down-conversion-home-last',\n",
            "       'sack_count-home-last', 'third-downs-home-last', 'comp-att-home-last',\n",
            "       'score-home-last', 'def-st-td-home-last', 'penalty_yards-home-last',\n",
            "       'espn-qbr-home-last', 'fourth-downs-home-last',\n",
            "       ...\n",
            "       'int-away-last-season', 'redzone_count-away-last-season',\n",
            "       'third-down-conversion-away-last-season', 'wintieloss-away-last-season',\n",
            "       'redzone_yards-away-last-season', 'rushing-to-passing-away-last-season',\n",
            "       'qb-elo-away-last-season', 'elo-away-last-season',\n",
            "       'rushing-attempts-away-last-season', 'turnovers-away-last-season'],\n",
            "      dtype='object', length=198)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[-5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "q1cW2BotzNGl",
        "outputId": "80723423-c827-4c39-ff3e-205901711cbb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      passing-yard-ratio-home-last  fourth-down-conversion-home-last  \\\n",
              "1095                      0.340909                               0.0   \n",
              "1130                      0.781250                               0.0   \n",
              "1294                      0.526448                               0.0   \n",
              "860                       0.833333                               0.5   \n",
              "3174                      0.797583                               0.5   \n",
              "\n",
              "      sack_count-home-last  third-downs-home-last  comp-att-home-last  \\\n",
              "1095                   2.0                   11.0            0.476190   \n",
              "1130                   1.0                   11.0            0.648649   \n",
              "1294                   0.0                   13.0            0.608696   \n",
              "860                    2.0                   10.0            0.658537   \n",
              "3174                   5.0                   13.0            0.611111   \n",
              "\n",
              "      score-home-last  def-st-td-home-last  penalty_yards-home-last  \\\n",
              "1095              9.0                  0.0                    125.0   \n",
              "1130             17.0                  0.0                     52.0   \n",
              "1294             19.0                  0.0                     55.0   \n",
              "860              14.0                  0.0                     97.0   \n",
              "3174             13.0                  0.0                     91.0   \n",
              "\n",
              "      espn-qbr-home-last  fourth-downs-home-last  ...  int-away-last-season  \\\n",
              "1095                10.1                     1.0  ...              0.897785   \n",
              "1130                78.2                     1.0  ...              0.759649   \n",
              "1294                55.3                     1.0  ...              0.693485   \n",
              "860                 65.6                     2.0  ...              0.833705   \n",
              "3174                56.5                     2.0  ...              1.192669   \n",
              "\n",
              "      redzone_count-away-last-season  third-down-conversion-away-last-season  \\\n",
              "1095                        2.093886                                0.426515   \n",
              "1130                        1.522655                                0.354709   \n",
              "1294                        2.087823                                0.430429   \n",
              "860                         1.319770                                0.382791   \n",
              "3174                        1.856504                                0.366459   \n",
              "\n",
              "      wintieloss-away-last-season  redzone_yards-away-last-season  \\\n",
              "1095                     0.601363                        4.105811   \n",
              "1130                     0.535521                        3.263845   \n",
              "1294                     0.756464                        3.898743   \n",
              "860                      0.580082                        3.570977   \n",
              "3174                     0.370586                        3.074356   \n",
              "\n",
              "      rushing-to-passing-away-last-season  qb-elo-away-last-season  \\\n",
              "1095                             0.462931              1638.082506   \n",
              "1130                             0.570606              1516.049052   \n",
              "1294                             0.358900              1592.089756   \n",
              "860                              0.628958              1534.047355   \n",
              "3174                             0.515197              1550.516945   \n",
              "\n",
              "      elo-away-last-season  rushing-attempts-away-last-season  \\\n",
              "1095           1630.509871                          28.464698   \n",
              "1130           1518.884043                          27.653366   \n",
              "1294           1601.272505                          26.035534   \n",
              "860            1526.884859                          28.130806   \n",
              "3174           1568.048144                          28.296528   \n",
              "\n",
              "      turnovers-away-last-season  \n",
              "1095                    1.452773  \n",
              "1130                    1.399217  \n",
              "1294                    1.124224  \n",
              "860                     1.637495  \n",
              "3174                    1.844286  \n",
              "\n",
              "[5 rows x 198 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c680216-ebcd-4734-8a05-7374741845e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>passing-yard-ratio-home-last</th>\n",
              "      <th>fourth-down-conversion-home-last</th>\n",
              "      <th>sack_count-home-last</th>\n",
              "      <th>third-downs-home-last</th>\n",
              "      <th>comp-att-home-last</th>\n",
              "      <th>score-home-last</th>\n",
              "      <th>def-st-td-home-last</th>\n",
              "      <th>penalty_yards-home-last</th>\n",
              "      <th>espn-qbr-home-last</th>\n",
              "      <th>fourth-downs-home-last</th>\n",
              "      <th>...</th>\n",
              "      <th>int-away-last-season</th>\n",
              "      <th>redzone_count-away-last-season</th>\n",
              "      <th>third-down-conversion-away-last-season</th>\n",
              "      <th>wintieloss-away-last-season</th>\n",
              "      <th>redzone_yards-away-last-season</th>\n",
              "      <th>rushing-to-passing-away-last-season</th>\n",
              "      <th>qb-elo-away-last-season</th>\n",
              "      <th>elo-away-last-season</th>\n",
              "      <th>rushing-attempts-away-last-season</th>\n",
              "      <th>turnovers-away-last-season</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>0.340909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.476190</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>10.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.897785</td>\n",
              "      <td>2.093886</td>\n",
              "      <td>0.426515</td>\n",
              "      <td>0.601363</td>\n",
              "      <td>4.105811</td>\n",
              "      <td>0.462931</td>\n",
              "      <td>1638.082506</td>\n",
              "      <td>1630.509871</td>\n",
              "      <td>28.464698</td>\n",
              "      <td>1.452773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.648649</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>78.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.759649</td>\n",
              "      <td>1.522655</td>\n",
              "      <td>0.354709</td>\n",
              "      <td>0.535521</td>\n",
              "      <td>3.263845</td>\n",
              "      <td>0.570606</td>\n",
              "      <td>1516.049052</td>\n",
              "      <td>1518.884043</td>\n",
              "      <td>27.653366</td>\n",
              "      <td>1.399217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>0.526448</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>55.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.693485</td>\n",
              "      <td>2.087823</td>\n",
              "      <td>0.430429</td>\n",
              "      <td>0.756464</td>\n",
              "      <td>3.898743</td>\n",
              "      <td>0.358900</td>\n",
              "      <td>1592.089756</td>\n",
              "      <td>1601.272505</td>\n",
              "      <td>26.035534</td>\n",
              "      <td>1.124224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.658537</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>65.6</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.833705</td>\n",
              "      <td>1.319770</td>\n",
              "      <td>0.382791</td>\n",
              "      <td>0.580082</td>\n",
              "      <td>3.570977</td>\n",
              "      <td>0.628958</td>\n",
              "      <td>1534.047355</td>\n",
              "      <td>1526.884859</td>\n",
              "      <td>28.130806</td>\n",
              "      <td>1.637495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3174</th>\n",
              "      <td>0.797583</td>\n",
              "      <td>0.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>56.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.192669</td>\n",
              "      <td>1.856504</td>\n",
              "      <td>0.366459</td>\n",
              "      <td>0.370586</td>\n",
              "      <td>3.074356</td>\n",
              "      <td>0.515197</td>\n",
              "      <td>1550.516945</td>\n",
              "      <td>1568.048144</td>\n",
              "      <td>28.296528</td>\n",
              "      <td>1.844286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 198 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c680216-ebcd-4734-8a05-7374741845e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c680216-ebcd-4734-8a05-7374741845e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c680216-ebcd-4734-8a05-7374741845e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(X_train.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czORH-PYyzt3",
        "outputId": "31b4c6b3-1ae6-493b-e811-80619fae4840"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['passing-yard-ratio-home-last', 'fourth-down-conversion-home-last', 'sack_count-home-last', 'third-downs-home-last', 'comp-att-home-last', 'score-home-last', 'def-st-td-home-last', 'penalty_yards-home-last', 'espn-qbr-home-last', 'fourth-downs-home-last', 'sack_yards-home-last', 'espn-qbr-missing-home-last', 'comp-home-last', 'rushing-yard-ratio-home-last', 'first-downs-home-last', 'att-home-last', 'total-yards-home-last', 'rushing-yards-home-last', 'passing-yards-home-last', 'possession-home-last', 'drives-home-last', 'penalty_count-home-last', 'fumbles-home-last', 'int-home-last', 'redzone_count-home-last', 'third-down-conversion-home-last', 'wintieloss-home-last', 'redzone_yards-home-last', 'rushing-to-passing-home-last', 'qb-elo-home-last', 'elo-home-last', 'rushing-attempts-home-last', 'turnovers-home-last', 'passing-yard-ratio-away-last', 'fourth-down-conversion-away-last', 'sack_count-away-last', 'third-downs-away-last', 'comp-att-away-last', 'score-away-last', 'def-st-td-away-last', 'penalty_yards-away-last', 'espn-qbr-away-last', 'fourth-downs-away-last', 'sack_yards-away-last', 'espn-qbr-missing-away-last', 'comp-away-last', 'rushing-yard-ratio-away-last', 'first-downs-away-last', 'att-away-last', 'total-yards-away-last', 'rushing-yards-away-last', 'passing-yards-away-last', 'possession-away-last', 'drives-away-last', 'penalty_count-away-last', 'fumbles-away-last', 'int-away-last', 'redzone_count-away-last', 'third-down-conversion-away-last', 'wintieloss-away-last', 'redzone_yards-away-last', 'rushing-to-passing-away-last', 'qb-elo-away-last', 'elo-away-last', 'rushing-attempts-away-last', 'turnovers-away-last', 'passing-yard-ratio-home-season', 'fourth-down-conversion-home-season', 'sack_count-home-season', 'third-downs-home-season', 'comp-att-home-season', 'score-home-season', 'def-st-td-home-season', 'penalty_yards-home-season', 'espn-qbr-home-season', 'fourth-downs-home-season', 'sack_yards-home-season', 'espn-qbr-missing-home-season', 'comp-home-season', 'rushing-yard-ratio-home-season', 'first-downs-home-season', 'att-home-season', 'total-yards-home-season', 'rushing-yards-home-season', 'passing-yards-home-season', 'possession-home-season', 'drives-home-season', 'penalty_count-home-season', 'fumbles-home-season', 'int-home-season', 'redzone_count-home-season', 'third-down-conversion-home-season', 'wintieloss-home-season', 'redzone_yards-home-season', 'rushing-to-passing-home-season', 'qb-elo-home-season', 'elo-home-season', 'rushing-attempts-home-season', 'turnovers-home-season', 'passing-yard-ratio-away-season', 'fourth-down-conversion-away-season', 'sack_count-away-season', 'third-downs-away-season', 'comp-att-away-season', 'score-away-season', 'def-st-td-away-season', 'penalty_yards-away-season', 'espn-qbr-away-season', 'fourth-downs-away-season', 'sack_yards-away-season', 'espn-qbr-missing-away-season', 'comp-away-season', 'rushing-yard-ratio-away-season', 'first-downs-away-season', 'att-away-season', 'total-yards-away-season', 'rushing-yards-away-season', 'passing-yards-away-season', 'possession-away-season', 'drives-away-season', 'penalty_count-away-season', 'fumbles-away-season', 'int-away-season', 'redzone_count-away-season', 'third-down-conversion-away-season', 'wintieloss-away-season', 'redzone_yards-away-season', 'rushing-to-passing-away-season', 'qb-elo-away-season', 'elo-away-season', 'rushing-attempts-away-season', 'turnovers-away-season', 'passing-yard-ratio-home-last-season', 'fourth-down-conversion-home-last-season', 'sack_count-home-last-season', 'third-downs-home-last-season', 'comp-att-home-last-season', 'score-home-last-season', 'def-st-td-home-last-season', 'penalty_yards-home-last-season', 'espn-qbr-home-last-season', 'fourth-downs-home-last-season', 'sack_yards-home-last-season', 'espn-qbr-missing-home-last-season', 'comp-home-last-season', 'rushing-yard-ratio-home-last-season', 'first-downs-home-last-season', 'att-home-last-season', 'total-yards-home-last-season', 'rushing-yards-home-last-season', 'passing-yards-home-last-season', 'possession-home-last-season', 'drives-home-last-season', 'penalty_count-home-last-season', 'fumbles-home-last-season', 'int-home-last-season', 'redzone_count-home-last-season', 'third-down-conversion-home-last-season', 'wintieloss-home-last-season', 'redzone_yards-home-last-season', 'rushing-to-passing-home-last-season', 'qb-elo-home-last-season', 'elo-home-last-season', 'rushing-attempts-home-last-season', 'turnovers-home-last-season', 'passing-yard-ratio-away-last-season', 'fourth-down-conversion-away-last-season', 'sack_count-away-last-season', 'third-downs-away-last-season', 'comp-att-away-last-season', 'score-away-last-season', 'def-st-td-away-last-season', 'penalty_yards-away-last-season', 'espn-qbr-away-last-season', 'fourth-downs-away-last-season', 'sack_yards-away-last-season', 'espn-qbr-missing-away-last-season', 'comp-away-last-season', 'rushing-yard-ratio-away-last-season', 'first-downs-away-last-season', 'att-away-last-season', 'total-yards-away-last-season', 'rushing-yards-away-last-season', 'passing-yards-away-last-season', 'possession-away-last-season', 'drives-away-last-season', 'penalty_count-away-last-season', 'fumbles-away-last-season', 'int-away-last-season', 'redzone_count-away-last-season', 'third-down-conversion-away-last-season', 'wintieloss-away-last-season', 'redzone_yards-away-last-season', 'rushing-to-passing-away-last-season', 'qb-elo-away-last-season', 'elo-away-last-season', 'rushing-attempts-away-last-season', 'turnovers-away-last-season']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "Lq0RrE0e2lo_",
        "outputId": "b9aca82f-0d41-4ddd-e216-2cecbd70584d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      passing-yard-ratio-home-last  fourth-down-conversion-home-last  \\\n",
              "1602                      0.700000                               0.0   \n",
              "805                       0.379939                               0.0   \n",
              "864                       0.776699                               0.5   \n",
              "321                       0.909722                               0.0   \n",
              "2119                      0.559767                               1.0   \n",
              "...                            ...                               ...   \n",
              "1095                      0.340909                               0.0   \n",
              "1130                      0.781250                               0.0   \n",
              "1294                      0.526448                               0.0   \n",
              "860                       0.833333                               0.5   \n",
              "3174                      0.797583                               0.5   \n",
              "\n",
              "      sack_count-home-last  third-downs-home-last  comp-att-home-last  \\\n",
              "1602                   2.0                   14.0            0.390244   \n",
              "805                    1.0                   16.0            0.600000   \n",
              "864                    6.0                   11.0            0.538462   \n",
              "321                   10.0                   14.0            0.630435   \n",
              "2119                   1.0                   10.0            0.586207   \n",
              "...                    ...                    ...                 ...   \n",
              "1095                   2.0                   11.0            0.476190   \n",
              "1130                   1.0                   11.0            0.648649   \n",
              "1294                   0.0                   13.0            0.608696   \n",
              "860                    2.0                   10.0            0.658537   \n",
              "3174                   5.0                   13.0            0.611111   \n",
              "\n",
              "      score-home-last  def-st-td-home-last  penalty_yards-home-last  \\\n",
              "1602              9.0                  0.0                     40.0   \n",
              "805              16.0                  0.0                     43.0   \n",
              "864              10.0                  0.0                     19.0   \n",
              "321              21.0                  0.0                     65.0   \n",
              "2119             38.0                  2.0                     58.0   \n",
              "...               ...                  ...                      ...   \n",
              "1095              9.0                  0.0                    125.0   \n",
              "1130             17.0                  0.0                     52.0   \n",
              "1294             19.0                  0.0                     55.0   \n",
              "860              14.0                  0.0                     97.0   \n",
              "3174             13.0                  0.0                     91.0   \n",
              "\n",
              "      espn-qbr-home-last  fourth-downs-home-last  ...  int-away-last-season  \\\n",
              "1602                35.9                     0.0  ...              1.576774   \n",
              "805                 49.8                     1.0  ...              1.109853   \n",
              "864                  2.7                     2.0  ...              1.208608   \n",
              "321                 25.4                     2.0  ...              1.293814   \n",
              "2119                64.7                     2.0  ...              1.153938   \n",
              "...                  ...                     ...  ...                   ...   \n",
              "1095                10.1                     1.0  ...              0.897785   \n",
              "1130                78.2                     1.0  ...              0.759649   \n",
              "1294                55.3                     1.0  ...              0.693485   \n",
              "860                 65.6                     2.0  ...              0.833705   \n",
              "3174                56.5                     2.0  ...              1.192669   \n",
              "\n",
              "      redzone_count-away-last-season  third-down-conversion-away-last-season  \\\n",
              "1602                        2.047183                                0.413667   \n",
              "805                         1.973580                                0.473099   \n",
              "864                         0.917766                                0.332858   \n",
              "321                         1.569618                                0.359685   \n",
              "2119                        0.000000                                0.304475   \n",
              "...                              ...                                     ...   \n",
              "1095                        2.093886                                0.426515   \n",
              "1130                        1.522655                                0.354709   \n",
              "1294                        2.087823                                0.430429   \n",
              "860                         1.319770                                0.382791   \n",
              "3174                        1.856504                                0.366459   \n",
              "\n",
              "      wintieloss-away-last-season  redzone_yards-away-last-season  \\\n",
              "1602                     0.478544                        4.245272   \n",
              "805                      0.519070                        3.625149   \n",
              "864                      0.259890                        2.447436   \n",
              "321                      0.808571                        3.191763   \n",
              "2119                     0.303715                        0.000000   \n",
              "...                           ...                             ...   \n",
              "1095                     0.601363                        4.105811   \n",
              "1130                     0.535521                        3.263845   \n",
              "1294                     0.756464                        3.898743   \n",
              "860                      0.580082                        3.570977   \n",
              "3174                     0.370586                        3.074356   \n",
              "\n",
              "      rushing-to-passing-away-last-season  qb-elo-away-last-season  \\\n",
              "1602                             0.649941              1548.540122   \n",
              "805                              0.449711              1461.577826   \n",
              "864                              1.028902              1452.836437   \n",
              "321                              0.778345              1617.987241   \n",
              "2119                             0.533694              1376.829643   \n",
              "...                                   ...                      ...   \n",
              "1095                             0.462931              1638.082506   \n",
              "1130                             0.570606              1516.049052   \n",
              "1294                             0.358900              1592.089756   \n",
              "860                              0.628958              1534.047355   \n",
              "3174                             0.515197              1550.516945   \n",
              "\n",
              "      elo-away-last-season  rushing-attempts-away-last-season  \\\n",
              "1602           1531.303823                          28.353264   \n",
              "805            1477.574285                          24.360151   \n",
              "864            1468.493557                          25.521062   \n",
              "321            1615.845337                          31.723362   \n",
              "2119           1386.421213                          24.573105   \n",
              "...                    ...                                ...   \n",
              "1095           1630.509871                          28.464698   \n",
              "1130           1518.884043                          27.653366   \n",
              "1294           1601.272505                          26.035534   \n",
              "860            1526.884859                          28.130806   \n",
              "3174           1568.048144                          28.296528   \n",
              "\n",
              "      turnovers-away-last-season  \n",
              "1602                    2.388245  \n",
              "805                     1.882400  \n",
              "864                     1.578388  \n",
              "321                     2.212106  \n",
              "2119                    1.635958  \n",
              "...                          ...  \n",
              "1095                    1.452773  \n",
              "1130                    1.399217  \n",
              "1294                    1.124224  \n",
              "860                     1.637495  \n",
              "3174                    1.844286  \n",
              "\n",
              "[3468 rows x 198 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85b7ab6d-f56b-4681-88fd-fb5b6604d79f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>passing-yard-ratio-home-last</th>\n",
              "      <th>fourth-down-conversion-home-last</th>\n",
              "      <th>sack_count-home-last</th>\n",
              "      <th>third-downs-home-last</th>\n",
              "      <th>comp-att-home-last</th>\n",
              "      <th>score-home-last</th>\n",
              "      <th>def-st-td-home-last</th>\n",
              "      <th>penalty_yards-home-last</th>\n",
              "      <th>espn-qbr-home-last</th>\n",
              "      <th>fourth-downs-home-last</th>\n",
              "      <th>...</th>\n",
              "      <th>int-away-last-season</th>\n",
              "      <th>redzone_count-away-last-season</th>\n",
              "      <th>third-down-conversion-away-last-season</th>\n",
              "      <th>wintieloss-away-last-season</th>\n",
              "      <th>redzone_yards-away-last-season</th>\n",
              "      <th>rushing-to-passing-away-last-season</th>\n",
              "      <th>qb-elo-away-last-season</th>\n",
              "      <th>elo-away-last-season</th>\n",
              "      <th>rushing-attempts-away-last-season</th>\n",
              "      <th>turnovers-away-last-season</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1602</th>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.390244</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>35.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.576774</td>\n",
              "      <td>2.047183</td>\n",
              "      <td>0.413667</td>\n",
              "      <td>0.478544</td>\n",
              "      <td>4.245272</td>\n",
              "      <td>0.649941</td>\n",
              "      <td>1548.540122</td>\n",
              "      <td>1531.303823</td>\n",
              "      <td>28.353264</td>\n",
              "      <td>2.388245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>0.379939</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>49.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.109853</td>\n",
              "      <td>1.973580</td>\n",
              "      <td>0.473099</td>\n",
              "      <td>0.519070</td>\n",
              "      <td>3.625149</td>\n",
              "      <td>0.449711</td>\n",
              "      <td>1461.577826</td>\n",
              "      <td>1477.574285</td>\n",
              "      <td>24.360151</td>\n",
              "      <td>1.882400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>0.776699</td>\n",
              "      <td>0.5</td>\n",
              "      <td>6.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.208608</td>\n",
              "      <td>0.917766</td>\n",
              "      <td>0.332858</td>\n",
              "      <td>0.259890</td>\n",
              "      <td>2.447436</td>\n",
              "      <td>1.028902</td>\n",
              "      <td>1452.836437</td>\n",
              "      <td>1468.493557</td>\n",
              "      <td>25.521062</td>\n",
              "      <td>1.578388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>0.909722</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.630435</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>25.4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.293814</td>\n",
              "      <td>1.569618</td>\n",
              "      <td>0.359685</td>\n",
              "      <td>0.808571</td>\n",
              "      <td>3.191763</td>\n",
              "      <td>0.778345</td>\n",
              "      <td>1617.987241</td>\n",
              "      <td>1615.845337</td>\n",
              "      <td>31.723362</td>\n",
              "      <td>2.212106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2119</th>\n",
              "      <td>0.559767</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.586207</td>\n",
              "      <td>38.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>64.7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.153938</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.304475</td>\n",
              "      <td>0.303715</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.533694</td>\n",
              "      <td>1376.829643</td>\n",
              "      <td>1386.421213</td>\n",
              "      <td>24.573105</td>\n",
              "      <td>1.635958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>0.340909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.476190</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>10.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.897785</td>\n",
              "      <td>2.093886</td>\n",
              "      <td>0.426515</td>\n",
              "      <td>0.601363</td>\n",
              "      <td>4.105811</td>\n",
              "      <td>0.462931</td>\n",
              "      <td>1638.082506</td>\n",
              "      <td>1630.509871</td>\n",
              "      <td>28.464698</td>\n",
              "      <td>1.452773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.648649</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>78.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.759649</td>\n",
              "      <td>1.522655</td>\n",
              "      <td>0.354709</td>\n",
              "      <td>0.535521</td>\n",
              "      <td>3.263845</td>\n",
              "      <td>0.570606</td>\n",
              "      <td>1516.049052</td>\n",
              "      <td>1518.884043</td>\n",
              "      <td>27.653366</td>\n",
              "      <td>1.399217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>0.526448</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>55.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.693485</td>\n",
              "      <td>2.087823</td>\n",
              "      <td>0.430429</td>\n",
              "      <td>0.756464</td>\n",
              "      <td>3.898743</td>\n",
              "      <td>0.358900</td>\n",
              "      <td>1592.089756</td>\n",
              "      <td>1601.272505</td>\n",
              "      <td>26.035534</td>\n",
              "      <td>1.124224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.658537</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>65.6</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.833705</td>\n",
              "      <td>1.319770</td>\n",
              "      <td>0.382791</td>\n",
              "      <td>0.580082</td>\n",
              "      <td>3.570977</td>\n",
              "      <td>0.628958</td>\n",
              "      <td>1534.047355</td>\n",
              "      <td>1526.884859</td>\n",
              "      <td>28.130806</td>\n",
              "      <td>1.637495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3174</th>\n",
              "      <td>0.797583</td>\n",
              "      <td>0.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>56.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.192669</td>\n",
              "      <td>1.856504</td>\n",
              "      <td>0.366459</td>\n",
              "      <td>0.370586</td>\n",
              "      <td>3.074356</td>\n",
              "      <td>0.515197</td>\n",
              "      <td>1550.516945</td>\n",
              "      <td>1568.048144</td>\n",
              "      <td>28.296528</td>\n",
              "      <td>1.844286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3468 rows × 198 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85b7ab6d-f56b-4681-88fd-fb5b6604d79f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85b7ab6d-f56b-4681-88fd-fb5b6604d79f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85b7ab6d-f56b-4681-88fd-fb5b6604d79f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_elo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTt9B2IEy8XB",
        "outputId": "d1d9dc68-c20b-43d5-b9e2-6836b2c6b8ca"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Elo (last)\": accuracy = 0.6470588235294118\n",
            "\"Elo (last)\": precision = 0.6695652173913044\n",
            "\"Elo (last)\": recall = 0.6581196581196581\n",
            "\"Elo (last)\": f1 = 0.6637931034482758\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 330    190\n",
            "  W (truth): 200    385\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_model_tree()"
      ],
      "metadata": {
        "id": "Qcu4EBaE1RET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fb23834-5d0a-4ca1-e865-84886cb9963b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment: train and predict ...\n",
            "\"Model Tree (train)\": accuracy = 0.68800461361015\n",
            "\"Model Tree (train)\": precision = 0.7046490428441203\n",
            "\"Model Tree (train)\": recall = 0.7808080808080808\n",
            "\"Model Tree (train)\": f1 = 0.740776233828462\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 840    648\n",
            "  W (truth): 434    1546\n",
            "-------------------------------------\n",
            "\"Model Tree\": accuracy = 0.616289592760181\n",
            "\"Model Tree\": precision = 0.6148359486447932\n",
            "\"Model Tree\": recall = 0.7367521367521368\n",
            "\"Model Tree\": f1 = 0.6702954898911353\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 250    270\n",
            "  W (truth): 154    431\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_lr()"
      ],
      "metadata": {
        "id": "52VMJmHhpkz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f26dd1c-00e1-482a-dd9c-22c4e3418bfb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment: train and predict ...\n",
            "\"Linear Regression (train)\": accuracy = 0.6473471741637832\n",
            "\"Linear Regression (train)\": precision = 0.6652116979484941\n",
            "\"Linear Regression (train)\": recall = 0.7696969696969697\n",
            "\"Linear Regression (train)\": f1 = 0.7136501990166236\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 721    767\n",
            "  W (truth): 456    1524\n",
            "-------------------------------------\n",
            "\"Linear Regression\": accuracy = 0.632579185520362\n",
            "\"Linear Regression\": precision = 0.6211096075778079\n",
            "\"Linear Regression\": recall = 0.7846153846153846\n",
            "\"Linear Regression\": f1 = 0.6933534743202417\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 240    280\n",
            "  W (truth): 126    459\n",
            "-------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_xgb()"
      ],
      "metadata": {
        "id": "HiWnb-6npmsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e26b36fa-f44c-4750-ced0-cb7e7ec0c3e7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment: train and predict ...\n",
            "\"XGBoost (train)\": accuracy = 0.998558246828143\n",
            "\"XGBoost (train)\": precision = 1.0\n",
            "\"XGBoost (train)\": recall = 0.9974747474747475\n",
            "\"XGBoost (train)\": f1 = 0.9987357774968395\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 1488    0\n",
            "  W (truth): 5    1975\n",
            "-------------------------------------\n",
            "\"XGBoost\": accuracy = 0.5864253393665159\n",
            "\"XGBoost\": precision = 0.5924855491329479\n",
            "\"XGBoost\": recall = 0.7008547008547008\n",
            "\"XGBoost\": f1 = 0.6421299921691463\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 238    282\n",
            "  W (truth): 175    410\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_lgb()"
      ],
      "metadata": {
        "id": "L5HjmgJ8ppg_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e402f7-cf4a-4de3-818a-fb34f9886205"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment: train and predict ...\n",
            "\"LightGBM (train)\": accuracy = 0.9968281430219147\n",
            "\"LightGBM (train)\": precision = 0.9969712266532055\n",
            "\"LightGBM (train)\": recall = 0.9974747474747475\n",
            "\"LightGBM (train)\": f1 = 0.9972229235041656\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 1482    6\n",
            "  W (truth): 5    1975\n",
            "-------------------------------------\n",
            "\"LightGBM\": accuracy = 0.604524886877828\n",
            "\"LightGBM\": precision = 0.6033519553072626\n",
            "\"LightGBM\": recall = 0.7384615384615385\n",
            "\"LightGBM\": f1 = 0.6641045349730976\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 236    284\n",
            "  W (truth): 153    432\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_svn()"
      ],
      "metadata": {
        "id": "qlQ_XF3vwPkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85de310-fb80-4d59-a128-ad7fcf649f73"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment: train and predict ...\n",
            "\"SVM Classifier (train)\": accuracy = 0.6375432525951558\n",
            "\"SVM Classifier (train)\": precision = 0.6321755027422303\n",
            "\"SVM Classifier (train)\": recall = 0.8732323232323232\n",
            "\"SVM Classifier (train)\": f1 = 0.7334040296924708\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 482    1006\n",
            "  W (truth): 251    1729\n",
            "-------------------------------------\n",
            "\"SVM Classifier\": accuracy = 0.6108597285067874\n",
            "\"SVM Classifier\": precision = 0.5877689694224235\n",
            "\"SVM Classifier\": recall = 0.8871794871794871\n",
            "\"SVM Classifier\": f1 = 0.7070844686648501\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 156    364\n",
            "  W (truth): 66    519\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_naive_bayes()"
      ],
      "metadata": {
        "id": "D_A-l3Wswtc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb045d2a-90b0-43d7-cf0f-0630cbe1b9eb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment: train and predict ...\n",
            "\"Naive Bayes (train)\": accuracy = 0.6239907727797002\n",
            "\"Naive Bayes (train)\": precision = 0.6443210930828351\n",
            "\"Naive Bayes (train)\": recall = 0.7621212121212121\n",
            "\"Naive Bayes (train)\": f1 = 0.6982878297084683\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 655    833\n",
            "  W (truth): 471    1509\n",
            "-------------------------------------\n",
            "\"Naive Bayes\": accuracy = 0.5972850678733032\n",
            "\"Naive Bayes\": precision = 0.5875\n",
            "\"Naive Bayes\": recall = 0.8034188034188035\n",
            "\"Naive Bayes\": f1 = 0.6787003610108303\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 190    330\n",
            "  W (truth): 115    470\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_gaussian_process()"
      ],
      "metadata": {
        "id": "q-jwR-VLVEhH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2525823-d330-45dc-8b46-717ee1997f9b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment: train and predict ...\n",
            "\"Gaussian Process (train)\": accuracy = 0.998558246828143\n",
            "\"Gaussian Process (train)\": precision = 1.0\n",
            "\"Gaussian Process (train)\": recall = 0.9974747474747475\n",
            "\"Gaussian Process (train)\": f1 = 0.9987357774968395\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 1488    0\n",
            "  W (truth): 5    1975\n",
            "-------------------------------------\n",
            "\"Gaussian Process\": accuracy = 0.47058823529411764\n",
            "\"Gaussian Process\": precision = 0.0\n",
            "\"Gaussian Process\": recall = 0.0\n",
            "\"Gaussian Process\": f1 = 0.0\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 520    0\n",
            "  W (truth): 585    0\n",
            "-------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_decision_tree()"
      ],
      "metadata": {
        "id": "sh8ryyzuy_4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f8623f-2f88-4d93-b098-a0c23cf7e47c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment: train and predict ...\n",
            "\"Decision Tree (train)\": accuracy = 0.998558246828143\n",
            "\"Decision Tree (train)\": precision = 1.0\n",
            "\"Decision Tree (train)\": recall = 0.9974747474747475\n",
            "\"Decision Tree (train)\": f1 = 0.9987357774968395\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 1488    0\n",
            "  W (truth): 5    1975\n",
            "-------------------------------------\n",
            "\"Decision Tree\": accuracy = 0.5828054298642534\n",
            "\"Decision Tree\": precision = 0.6\n",
            "\"Decision Tree\": recall = 0.6358974358974359\n",
            "\"Decision Tree\": f1 = 0.6174273858921161\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 272    248\n",
            "  W (truth): 213    372\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_adaboost()"
      ],
      "metadata": {
        "id": "q0_rEMQc5VAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef69fe4-08a0-40a1-983a-2618cd194b7f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment: train and predict ...\n",
            "\"AdaBoost (train)\": accuracy = 0.6972318339100346\n",
            "\"AdaBoost (train)\": precision = 0.7123287671232876\n",
            "\"AdaBoost (train)\": recall = 0.7878787878787878\n",
            "\"AdaBoost (train)\": f1 = 0.7482014388489209\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 858    630\n",
            "  W (truth): 420    1560\n",
            "-------------------------------------\n",
            "\"AdaBoost\": accuracy = 0.5936651583710407\n",
            "\"AdaBoost\": precision = 0.6008902077151336\n",
            "\"AdaBoost\": recall = 0.6923076923076923\n",
            "\"AdaBoost\": f1 = 0.6433677521842733\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 251    269\n",
            "  W (truth): 180    405\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_random_forest()"
      ],
      "metadata": {
        "id": "bhnkd6yb-ZE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cde46c02-80ef-45cc-971c-dde703941c0d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment: train and predict ...\n",
            "\"Random Forest (train)\": accuracy = 0.998558246828143\n",
            "\"Random Forest (train)\": precision = 1.0\n",
            "\"Random Forest (train)\": recall = 0.9974747474747475\n",
            "\"Random Forest (train)\": f1 = 0.9987357774968395\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 1488    0\n",
            "  W (truth): 5    1975\n",
            "-------------------------------------\n",
            "\"Random Forest\": accuracy = 0.6153846153846154\n",
            "\"Random Forest\": precision = 0.6123595505617978\n",
            "\"Random Forest\": recall = 0.7452991452991453\n",
            "\"Random Forest\": f1 = 0.6723207401696223\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 244    276\n",
            "  W (truth): 149    436\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_qda()"
      ],
      "metadata": {
        "id": "TAdIyWvfZv1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18de1b4a-3e15-4fcf-9e4a-66b5cf03df49"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment: train and predict ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Quadratic Discriminant Analysis (train)\": accuracy = 0.5717993079584776\n",
            "\"Quadratic Discriminant Analysis (train)\": precision = 0.5714285714285714\n",
            "\"Quadratic Discriminant Analysis (train)\": recall = 1.0\n",
            "\"Quadratic Discriminant Analysis (train)\": f1 = 0.7272727272727273\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 3    1485\n",
            "  W (truth): 0    1980\n",
            "-------------------------------------\n",
            "\"Quadratic Discriminant Analysis\": accuracy = 0.5294117647058824\n",
            "\"Quadratic Discriminant Analysis\": precision = 0.5294117647058824\n",
            "\"Quadratic Discriminant Analysis\": recall = 1.0\n",
            "\"Quadratic Discriminant Analysis\": f1 = 0.6923076923076924\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 0    520\n",
            "  W (truth): 0    585\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_nn()"
      ],
      "metadata": {
        "id": "Oiv52EH-T3WQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66328d8-8906-412a-c75b-247daf260ced"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "87/87 [==============================] - 2s 9ms/step - loss: 43.4443 - accuracy: 0.5090 - val_loss: 3.9139 - val_accuracy: 0.6326\n",
            "Epoch 2/15\n",
            "87/87 [==============================] - 0s 5ms/step - loss: 8.8461 - accuracy: 0.5151 - val_loss: 3.3982 - val_accuracy: 0.4841\n",
            "Epoch 3/15\n",
            "87/87 [==============================] - 0s 5ms/step - loss: 4.3564 - accuracy: 0.5364 - val_loss: 2.8026 - val_accuracy: 0.6066\n",
            "Epoch 4/15\n",
            "87/87 [==============================] - 0s 6ms/step - loss: 3.1919 - accuracy: 0.5256 - val_loss: 2.5659 - val_accuracy: 0.6110\n",
            "Epoch 5/15\n",
            "87/87 [==============================] - 0s 5ms/step - loss: 2.7316 - accuracy: 0.5202 - val_loss: 2.4929 - val_accuracy: 0.6225\n",
            "Epoch 6/15\n",
            "87/87 [==============================] - 0s 5ms/step - loss: 2.5699 - accuracy: 0.5382 - val_loss: 2.4412 - val_accuracy: 0.6138\n",
            "Epoch 7/15\n",
            "87/87 [==============================] - 0s 5ms/step - loss: 2.4927 - accuracy: 0.5429 - val_loss: 2.3922 - val_accuracy: 0.6268\n",
            "Epoch 8/15\n",
            "87/87 [==============================] - 0s 5ms/step - loss: 2.4091 - accuracy: 0.5440 - val_loss: 2.3443 - val_accuracy: 0.6196\n",
            "Epoch 9/15\n",
            "87/87 [==============================] - 0s 6ms/step - loss: 2.3672 - accuracy: 0.5469 - val_loss: 2.3008 - val_accuracy: 0.6153\n",
            "Epoch 10/15\n",
            "87/87 [==============================] - 0s 5ms/step - loss: 2.3092 - accuracy: 0.5512 - val_loss: 2.2541 - val_accuracy: 0.6138\n",
            "Epoch 11/15\n",
            "87/87 [==============================] - 0s 5ms/step - loss: 2.2579 - accuracy: 0.5591 - val_loss: 2.2091 - val_accuracy: 0.6138\n",
            "Epoch 12/15\n",
            "87/87 [==============================] - 0s 5ms/step - loss: 2.2157 - accuracy: 0.5552 - val_loss: 2.1713 - val_accuracy: 0.6052\n",
            "Epoch 13/15\n",
            "87/87 [==============================] - 0s 5ms/step - loss: 2.1693 - accuracy: 0.5526 - val_loss: 2.1302 - val_accuracy: 0.6138\n",
            "Epoch 14/15\n",
            "87/87 [==============================] - 0s 5ms/step - loss: 2.1389 - accuracy: 0.5497 - val_loss: 2.0895 - val_accuracy: 0.6138\n",
            "Epoch 15/15\n",
            "87/87 [==============================] - 0s 5ms/step - loss: 2.0888 - accuracy: 0.5530 - val_loss: 2.0481 - val_accuracy: 0.6138\n",
            "35/35 [==============================] - 0s 3ms/step\n",
            "\"Neural Network\": accuracy = 0.5294117647058824\n",
            "\"Neural Network\": precision = 0.5294117647058824\n",
            "\"Neural Network\": recall = 1.0\n",
            "\"Neural Network\": f1 = 0.6923076923076924\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 0    520\n",
            "  W (truth): 0    585\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_tabnet()"
      ],
      "metadata": {
        "id": "BLrYI9CCjMSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63cb1ada-9699-45cd-a91f-abbe2374f6ad"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2774, 198)\n",
            "(694, 198)\n",
            "(2774,)\n",
            "(694,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.02961 | val_0_auc: 0.53042 | val_1_auc: 0.52435 |  0:00:00s\n",
            "epoch 1  | loss: 0.83235 | val_0_auc: 0.49067 | val_1_auc: 0.45128 |  0:00:01s\n",
            "epoch 2  | loss: 0.75456 | val_0_auc: 0.5317  | val_1_auc: 0.52249 |  0:00:02s\n",
            "epoch 3  | loss: 0.7505  | val_0_auc: 0.48917 | val_1_auc: 0.41566 |  0:00:03s\n",
            "epoch 4  | loss: 0.72513 | val_0_auc: 0.47741 | val_1_auc: 0.43415 |  0:00:03s\n",
            "epoch 5  | loss: 0.71408 | val_0_auc: 0.4932  | val_1_auc: 0.51246 |  0:00:04s\n",
            "epoch 6  | loss: 0.70284 | val_0_auc: 0.47895 | val_1_auc: 0.49232 |  0:00:04s\n",
            "epoch 7  | loss: 0.69959 | val_0_auc: 0.50893 | val_1_auc: 0.5466  |  0:00:05s\n",
            "epoch 8  | loss: 0.68852 | val_0_auc: 0.52728 | val_1_auc: 0.51747 |  0:00:05s\n",
            "epoch 9  | loss: 0.6902  | val_0_auc: 0.52357 | val_1_auc: 0.50361 |  0:00:06s\n",
            "epoch 10 | loss: 0.68496 | val_0_auc: 0.53305 | val_1_auc: 0.50577 |  0:00:06s\n",
            "epoch 11 | loss: 0.68378 | val_0_auc: 0.54092 | val_1_auc: 0.54074 |  0:00:07s\n",
            "epoch 12 | loss: 0.68477 | val_0_auc: 0.54645 | val_1_auc: 0.55494 |  0:00:07s\n",
            "epoch 13 | loss: 0.68056 | val_0_auc: 0.53387 | val_1_auc: 0.53043 |  0:00:08s\n",
            "epoch 14 | loss: 0.68298 | val_0_auc: 0.53157 | val_1_auc: 0.52509 |  0:00:08s\n",
            "epoch 15 | loss: 0.68109 | val_0_auc: 0.52403 | val_1_auc: 0.49272 |  0:00:09s\n",
            "epoch 16 | loss: 0.67514 | val_0_auc: 0.49135 | val_1_auc: 0.52346 |  0:00:09s\n",
            "epoch 17 | loss: 0.67361 | val_0_auc: 0.51048 | val_1_auc: 0.4794  |  0:00:10s\n",
            "epoch 18 | loss: 0.67965 | val_0_auc: 0.51021 | val_1_auc: 0.50658 |  0:00:11s\n",
            "epoch 19 | loss: 0.68044 | val_0_auc: 0.53233 | val_1_auc: 0.54001 |  0:00:11s\n",
            "epoch 20 | loss: 0.67611 | val_0_auc: 0.51996 | val_1_auc: 0.50035 |  0:00:12s\n",
            "epoch 21 | loss: 0.67488 | val_0_auc: 0.50786 | val_1_auc: 0.48469 |  0:00:12s\n",
            "epoch 22 | loss: 0.67806 | val_0_auc: 0.49876 | val_1_auc: 0.51007 |  0:00:13s\n",
            "\n",
            "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_1_auc = 0.55494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"TabNet\": accuracy = 0.5375565610859728\n",
            "\"TabNet\": precision = 0.5564024390243902\n",
            "\"TabNet\": recall = 0.6239316239316239\n",
            "\"TabNet\": f1 = 0.5882352941176471\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 229    291\n",
            "  W (truth): 220    365\n",
            "-------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'metrics': {'accuracy': 0.5375565610859728,\n",
              "  'precision': 0.5564024390243902,\n",
              "  'recall': 0.6239316239316239,\n",
              "  'f1': 0.5882352941176471},\n",
              " 'pred': array([0, 0, 0, ..., 1, 1, 1]),\n",
              " 'proba': array([[0.60913104, 0.390869  ],\n",
              "        [0.5141538 , 0.48584625],\n",
              "        [0.7215219 , 0.27847806],\n",
              "        ...,\n",
              "        [0.05820589, 0.9417941 ],\n",
              "        [0.00671227, 0.99328774],\n",
              "        [0.22874215, 0.7712579 ]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_ensemble(['XGBoost', 'AdaBoost', 'TabNet', 'Linear Regression', 'LightGBM'])"
      ],
      "metadata": {
        "id": "Um8wHZsyopDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b37366a-1766-4548-86d2-84226f9d5f4e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Ensemble/add\": accuracy = 0.6072398190045248\n",
            "\"Ensemble/add\": precision = 0.5984354628422425\n",
            "\"Ensemble/add\": recall = 0.7846153846153846\n",
            "\"Ensemble/add\": f1 = 0.6789940828402367\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 212    308\n",
            "  W (truth): 126    459\n",
            "-------------------------------------\n",
            "\"Ensemble/mult\": accuracy = 0.6054298642533936\n",
            "\"Ensemble/mult\": precision = 0.5958815958815958\n",
            "\"Ensemble/mult\": recall = 0.7914529914529914\n",
            "\"Ensemble/mult\": f1 = 0.6798825256975036\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 206    314\n",
            "  W (truth): 122    463\n",
            "-------------------------------------\n",
            "\"Ensemble/vote\": accuracy = 0.6135746606334842\n",
            "\"Ensemble/vote\": precision = 0.6064690026954178\n",
            "\"Ensemble/vote\": recall = 0.7692307692307693\n",
            "\"Ensemble/vote\": f1 = 0.6782215523737755\n",
            "-------------------------------------\n",
            "Confusion Matrix:\n",
            "-------------------------------------\n",
            "               L      W (predicted)\n",
            "  L (truth): 228    292\n",
            "  W (truth): 135    450\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_results"
      ],
      "metadata": {
        "id": "Rcnj4SDDcXnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab08902a-2a4d-4588-ac52-3e61757070dc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Elo (last)': {'metrics': {'accuracy': 0.6470588235294118,\n",
              "   'precision': 0.6695652173913044,\n",
              "   'recall': 0.6581196581196581,\n",
              "   'f1': 0.6637931034482758}},\n",
              " 'Model Tree': {'metrics': {'accuracy': 0.616289592760181,\n",
              "   'precision': 0.6148359486447932,\n",
              "   'recall': 0.7367521367521368,\n",
              "   'f1': 0.6702954898911353},\n",
              "  'pred': array([1, 0, 0, ..., 1, 1, 0]),\n",
              "  'proba': None},\n",
              " 'Linear Regression': {'metrics': {'accuracy': 0.632579185520362,\n",
              "   'precision': 0.6211096075778079,\n",
              "   'recall': 0.7846153846153846,\n",
              "   'f1': 0.6933534743202417},\n",
              "  'pred': array([1, 0, 0, ..., 1, 0, 0]),\n",
              "  'proba': array([[0.1625906 , 0.8374094 ],\n",
              "         [0.67236778, 0.32763222],\n",
              "         [0.56642001, 0.43357999],\n",
              "         ...,\n",
              "         [0.38313109, 0.61686891],\n",
              "         [0.56575039, 0.43424961],\n",
              "         [0.57913297, 0.42086703]])},\n",
              " 'XGBoost': {'metrics': {'accuracy': 0.5864253393665159,\n",
              "   'precision': 0.5924855491329479,\n",
              "   'recall': 0.7008547008547008,\n",
              "   'f1': 0.6421299921691463},\n",
              "  'pred': array([1, 0, 0, ..., 1, 0, 0]),\n",
              "  'proba': array([[0.01303107, 0.98696893],\n",
              "         [0.8438487 , 0.1561513 ],\n",
              "         [0.8925556 , 0.1074444 ],\n",
              "         ...,\n",
              "         [0.21674395, 0.78325605],\n",
              "         [0.8003689 , 0.19963108],\n",
              "         [0.6995591 , 0.3004409 ]], dtype=float32)},\n",
              " 'LightGBM': {'metrics': {'accuracy': 0.604524886877828,\n",
              "   'precision': 0.6033519553072626,\n",
              "   'recall': 0.7384615384615385,\n",
              "   'f1': 0.6641045349730976},\n",
              "  'pred': array([1, 0, 0, ..., 1, 1, 1]),\n",
              "  'proba': array([[0.29195279, 0.70804721],\n",
              "         [0.71163397, 0.28836603],\n",
              "         [0.70415386, 0.29584614],\n",
              "         ...,\n",
              "         [0.25849652, 0.74150348],\n",
              "         [0.29856007, 0.70143993],\n",
              "         [0.27509599, 0.72490401]])},\n",
              " 'SVM Classifier': {'metrics': {'accuracy': 0.6108597285067874,\n",
              "   'precision': 0.5877689694224235,\n",
              "   'recall': 0.8871794871794871,\n",
              "   'f1': 0.7070844686648501},\n",
              "  'pred': array([1, 1, 1, ..., 1, 1, 1]),\n",
              "  'proba': array([[0.26861723, 0.73138277],\n",
              "         [0.51992876, 0.48007124],\n",
              "         [0.39316114, 0.60683886],\n",
              "         ...,\n",
              "         [0.34763474, 0.65236526],\n",
              "         [0.46918331, 0.53081669],\n",
              "         [0.53700491, 0.46299509]])},\n",
              " 'Naive Bayes': {'metrics': {'accuracy': 0.5972850678733032,\n",
              "   'precision': 0.5875,\n",
              "   'recall': 0.8034188034188035,\n",
              "   'f1': 0.6787003610108303},\n",
              "  'pred': array([1, 0, 1, ..., 1, 1, 1]),\n",
              "  'proba': array([[1.72142810e-03, 9.98278572e-01],\n",
              "         [9.99188134e-01, 8.11866403e-04],\n",
              "         [4.52045709e-02, 9.54795429e-01],\n",
              "         ...,\n",
              "         [4.23691185e-03, 9.95763088e-01],\n",
              "         [4.35399340e-03, 9.95646007e-01],\n",
              "         [4.79881556e-01, 5.20118444e-01]])},\n",
              " 'Gaussian Process': {'metrics': {'accuracy': 0.47058823529411764,\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0.0},\n",
              "  'pred': array([0, 0, 0, ..., 0, 0, 0]),\n",
              "  'proba': None},\n",
              " 'Decision Tree': {'metrics': {'accuracy': 0.5828054298642534,\n",
              "   'precision': 0.6,\n",
              "   'recall': 0.6358974358974359,\n",
              "   'f1': 0.6174273858921161},\n",
              "  'pred': array([1, 0, 0, ..., 1, 0, 0]),\n",
              "  'proba': array([[0., 1.],\n",
              "         [1., 0.],\n",
              "         [1., 0.],\n",
              "         ...,\n",
              "         [0., 1.],\n",
              "         [1., 0.],\n",
              "         [1., 0.]])},\n",
              " 'AdaBoost': {'metrics': {'accuracy': 0.5936651583710407,\n",
              "   'precision': 0.6008902077151336,\n",
              "   'recall': 0.6923076923076923,\n",
              "   'f1': 0.6433677521842733},\n",
              "  'pred': array([1, 0, 0, ..., 0, 0, 0]),\n",
              "  'proba': array([[0.49403791, 0.50596209],\n",
              "         [0.50391377, 0.49608623],\n",
              "         [0.50174063, 0.49825937],\n",
              "         ...,\n",
              "         [0.50225245, 0.49774755],\n",
              "         [0.50258444, 0.49741556],\n",
              "         [0.50328884, 0.49671116]])},\n",
              " 'Random Forest': {'metrics': {'accuracy': 0.6153846153846154,\n",
              "   'precision': 0.6123595505617978,\n",
              "   'recall': 0.7452991452991453,\n",
              "   'f1': 0.6723207401696223},\n",
              "  'pred': array([1, 0, 0, ..., 1, 1, 0]),\n",
              "  'proba': array([[0.25, 0.75],\n",
              "         [0.7 , 0.3 ],\n",
              "         [0.53, 0.47],\n",
              "         ...,\n",
              "         [0.34, 0.66],\n",
              "         [0.44, 0.56],\n",
              "         [0.5 , 0.5 ]])},\n",
              " 'Quadratic Discriminant Analysis': {'metrics': {'accuracy': 0.5294117647058824,\n",
              "   'precision': 0.5294117647058824,\n",
              "   'recall': 1.0,\n",
              "   'f1': 0.6923076923076924},\n",
              "  'pred': array([1, 1, 1, ..., 1, 1, 1]),\n",
              "  'proba': array([[0.00000000e+000, 1.00000000e+000],\n",
              "         [0.00000000e+000, 1.00000000e+000],\n",
              "         [0.00000000e+000, 1.00000000e+000],\n",
              "         ...,\n",
              "         [0.00000000e+000, 1.00000000e+000],\n",
              "         [1.97626258e-323, 1.00000000e+000],\n",
              "         [4.17230558e-300, 1.00000000e+000]])},\n",
              " 'Neural Network': {'metrics': {'accuracy': 0.5294117647058824,\n",
              "   'precision': 0.5294117647058824,\n",
              "   'recall': 1.0,\n",
              "   'f1': 0.6923076923076924},\n",
              "  'pred': array([1, 1, 1, ..., 1, 1, 1]),\n",
              "  'proba': array([[0.4100312 , 0.5899688 ],\n",
              "         [0.4229562 , 0.57704383],\n",
              "         [0.41868466, 0.58131534],\n",
              "         ...,\n",
              "         [0.44236714, 0.55763286],\n",
              "         [0.44702172, 0.55297834],\n",
              "         [0.44389874, 0.55610126]], dtype=float32)},\n",
              " 'TabNet': {'metrics': {'accuracy': 0.5375565610859728,\n",
              "   'precision': 0.5564024390243902,\n",
              "   'recall': 0.6239316239316239,\n",
              "   'f1': 0.5882352941176471},\n",
              "  'pred': array([0, 0, 0, ..., 1, 1, 1]),\n",
              "  'proba': array([[0.60913104, 0.390869  ],\n",
              "         [0.5141538 , 0.48584625],\n",
              "         [0.7215219 , 0.27847806],\n",
              "         ...,\n",
              "         [0.05820589, 0.9417941 ],\n",
              "         [0.00671227, 0.99328774],\n",
              "         [0.22874215, 0.7712579 ]], dtype=float32)},\n",
              " 'Ensemble/add': {'metrics': {'accuracy': 0.6072398190045248,\n",
              "   'precision': 0.5984354628422425,\n",
              "   'recall': 0.7846153846153846,\n",
              "   'f1': 0.6789940828402367}},\n",
              " 'Ensemble/mult': {'metrics': {'accuracy': 0.6054298642533936,\n",
              "   'precision': 0.5958815958815958,\n",
              "   'recall': 0.7914529914529914,\n",
              "   'f1': 0.6798825256975036}},\n",
              " 'Ensemble/vote': {'metrics': {'accuracy': 0.6135746606334842,\n",
              "   'precision': 0.6064690026954178,\n",
              "   'recall': 0.7692307692307693,\n",
              "   'f1': 0.6782215523737755}}}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}