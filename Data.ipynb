{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25847076",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "This Jupyter Notebook can be executed in one of two ways:\n",
    "\n",
    "(1) set definition_only to True, and it will define Part_I(), Part_II(), ..., Part_XI(). You can then execute Part_All() in one shot at the end.\n",
    "\n",
    "(2) set definition_only to False, in which case as the parts are defined, they will be executed.\n",
    "\n",
    "Option (1) is better for experimentation. Option (2) is better for going through the flow. If you are reading this, I recommend the second option (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85bd1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "definition_only = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893e12f4",
   "metadata": {},
   "source": [
    "# Global Settings\n",
    "\n",
    "This controls the behavior of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095a4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRESETS_100_100_original = {\n",
    "    'filename': 'tabular-100-100-original.csv',\n",
    "    'weekly_alpha': 1.00,\n",
    "    'season_cliff': 1.00,\n",
    "    'normalize': False\n",
    "}\n",
    "\n",
    "PRESETS_100_100_norm = {\n",
    "    'filename': 'tabular-100-100-norm.csv',\n",
    "    'weekly_alpha': 1.00,\n",
    "    'season_cliff': 1.00,\n",
    "    'normalize': True\n",
    "}\n",
    "\n",
    "PRESETS_095_050_norm = {\n",
    "    'filename': 'tabular-095-050-norm.csv',\n",
    "    'weekly_alpha': 0.95,\n",
    "    'season_cliff': 0.50,\n",
    "    'normalize': True\n",
    "}\n",
    "\n",
    "PRESETS_095_050_original = {\n",
    "    'filename': 'tabular-095-050-original.csv',\n",
    "    'weekly_alpha': 0.95,\n",
    "    'season_cliff': 0.50,\n",
    "    'normalize': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38689d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL = PRESETS_095_050_original  # the key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ebb566",
   "metadata": {},
   "source": [
    "# Part I -- Five Fifty Eight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85f1152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64ce030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_to_canon_list = [\n",
    "    ('Browns', 'CLE'), ('Chiefs', 'KC'), ('Steelers', 'PIT'),\n",
    "    ('Lions', 'DET'), ('Titans', 'TEN'), ('Rams', 'LAR'),\n",
    "    ('Patriots', 'NE'), ('Buccaneers', 'TB'), ('Panthers', 'CAR'),\n",
    "    ('Texans', 'HOU'), ('Packers', 'GB'), ('Cardinals', 'ARI'),\n",
    "    ('Jaguars', 'JAX'), ('Giants', 'NYG'), ('Commanders', 'WSH'),\n",
    "    ('Raiders', 'LV'), ('Falcons', 'ATL'), ('Bears', 'CHI'),\n",
    "    ('Bengals', 'CIN'), ('Colts', 'IND'), ('Dolphins', 'MIA'),\n",
    "    ('Vikings', 'MIN'), ('Eagles', 'PHI'), ('Ravens', 'BAL'),\n",
    "    ('Seahawks', 'SEA'), ('Broncos', 'DEN'), ('Jets', 'NYJ'),\n",
    "    ('Chargers', 'LAC'), ('Cowboys', 'DAL'), ('Bills', 'BUF'),\n",
    "    ('Saints', 'NO'), ('49ers', 'SF')\n",
    "]\n",
    "abbrev_to_canon_list = [\n",
    "    ('OAK', 'LV'),  # Oakland Raiders --> Las Vegas Raiders\n",
    "    ('SD', 'LAC'),  # San Diego Chargers --> Los Angeles Chargers\n",
    "    ('STL', 'LAR'),  # St Louis Rams --> Los Angeles Rams \n",
    "]\n",
    "full_to_canon_dict = { x: y for x, y in full_to_canon_list }\n",
    "abbrev_to_canon_dict = { x: y for x, y in abbrev_to_canon_list }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a08727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'season', 'neutral', 'playoff', 'team1', 'team2', 'elo1_pre',\n",
      "       'elo2_pre', 'elo_prob1', 'elo_prob2', 'elo1_post', 'elo2_post',\n",
      "       'qbelo1_pre', 'qbelo2_pre', 'qb1', 'qb2', 'qb1_value_pre',\n",
      "       'qb2_value_pre', 'qb1_adj', 'qb2_adj', 'qbelo_prob1', 'qbelo_prob2',\n",
      "       'qb1_game_value', 'qb2_game_value', 'qb1_value_post', 'qb2_value_post',\n",
      "       'qbelo1_post', 'qbelo2_post', 'score1', 'score2', 'quality',\n",
      "       'importance', 'total_rating'],\n",
      "      dtype='object')\n",
      "['PIT' 'ARI' 'CAR' 'CLE' 'DET' 'GB' 'HOU' 'JAX' 'KC' 'LAR' 'NE' 'NYG' 'TB'\n",
      " 'TEN' 'LV' 'WSH' 'ATL' 'BAL' 'CHI' 'CIN' 'DAL' 'DEN' 'IND' 'LAC' 'MIA'\n",
      " 'MIN' 'NYJ' 'PHI' 'SEA' 'SF' 'BUF' 'NO']\n"
     ]
    }
   ],
   "source": [
    "def Part_I():\n",
    "    global fivethirtyeight\n",
    "    fivethirtyeight = pd.read_csv('data/538/538-elo.csv')\n",
    "    print(fivethirtyeight.columns)\n",
    "    fivethirtyeight = pd.DataFrame(fivethirtyeight[fivethirtyeight['season'] >= 2006])\n",
    "    fivethirtyeight = fivethirtyeight.reset_index(drop=True)\n",
    "    fivethirtyeight['team1'].replace(abbrev_to_canon_dict, inplace=True)\n",
    "    fivethirtyeight['team2'].replace(abbrev_to_canon_dict, inplace=True)\n",
    "    fivethirtyeight.insert(6, 'rivalry', fivethirtyeight['team1'] + '-' + fivethirtyeight['team2'])\n",
    "    fivethirtyeight = fivethirtyeight.sort_values(['date', 'rivalry'])\n",
    "    fivethirtyeight.reset_index(drop=True)\n",
    "    league = fivethirtyeight['team1'].unique()\n",
    "    assert(len(league) == 32)  # 32-team league\n",
    "    print(league)\n",
    "\n",
    "if not definition_only:\n",
    "    Part_I()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678cbb0e",
   "metadata": {},
   "source": [
    "# Part II -- ESPN NFL Team Stat (Kaggle Dataset)\n",
    "\n",
    "Our data from ESPN is missing the following games (a data error on the ESPN side):\n",
    "\n",
    "> 2007-12-30,DAL-WSH\n",
    "\n",
    "> 2010-12-23,CAR-PIT\n",
    "\n",
    "> 2012-01-01,ATL-TB\n",
    "\n",
    "We choose to just delete them instead of recreating them. With this correction, the Kaggle dataset is consistent with the ESPN dataset, with 4573 entries (out of 4576) entries from 2006 to 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63bf2e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'away', 'home', 'rivalry', 'first_downs_away',\n",
      "       'first_downs_home', 'third_downs_away', 'third_downs_home',\n",
      "       'fourth_downs_away', 'fourth_downs_home', 'passing_yards_away',\n",
      "       'passing_yards_home', 'rushing_yards_away', 'rushing_yards_home',\n",
      "       'total_yards_away', 'total_yards_home', 'comp_att_away',\n",
      "       'comp_att_home', 'sacks_away', 'sacks_home', 'rushing_attempts_away',\n",
      "       'rushing_attempts_home', 'fumbles_away', 'fumbles_home', 'int_away',\n",
      "       'int_home', 'turnovers_away', 'turnovers_home', 'penalties_away',\n",
      "       'penalties_home', 'redzone_away', 'redzone_home', 'drives_away',\n",
      "       'drives_home', 'def_st_td_away', 'def_st_td_home', 'possession_away',\n",
      "       'possession_home', 'score_away', 'score_home'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def Part_II():\n",
    "    global team_stat\n",
    "    team_stat = pd.read_csv('data/kaggle/team-stat.csv')\n",
    "    team_stat = pd.DataFrame(team_stat[team_stat['date'] > '2006-06-30'])  # 2002 season\n",
    "    team_stat['home'].replace(full_to_canon_dict, inplace=True)\n",
    "    team_stat['away'].replace(full_to_canon_dict, inplace=True)\n",
    "    team_stat.insert(3, 'rivalry', team_stat['home'] + '-' + team_stat['away'])\n",
    "    team_stat = team_stat.sort_values(['date', 'rivalry'])\n",
    "    team_stat = team_stat.reset_index(drop=True)\n",
    "    \n",
    "    def colon_to_seconds(s):  # 34:56 --> 34 * 60 + 56\n",
    "        return 60 * int(s.split(':')[0]) + int(s.split(':')[1])\n",
    "    \n",
    "    team_stat['possession_away'] = team_stat['possession_away'].apply(colon_to_seconds)\n",
    "    team_stat['possession_home'] = team_stat['possession_home'].apply(colon_to_seconds)\n",
    "    print(team_stat.columns)\n",
    "    \n",
    "if not definition_only:\n",
    "    Part_II()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef93a3",
   "metadata": {},
   "source": [
    "# Part III -- More Lookup Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93b3927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Part_III():\n",
    "\n",
    "    global homes_dict, aways_dict, team_dates_dict\n",
    "    \n",
    "    # generate homes_dict['PITT|2006-09-07'] --> index into the actual game\n",
    "    # generate aways_dict['MIA|2006-09-07'] --> index into the actual game\n",
    "\n",
    "    games = team_stat[['date', 'rivalry']]\n",
    "\n",
    "    homes_dict = {}\n",
    "    aways_dict = {}\n",
    "    for index, r in games.iterrows():\n",
    "        date = r['date']\n",
    "        rivals = r['rivalry'].split('-')\n",
    "        homes_dict[f'{rivals[0]}|{date}'] = index\n",
    "        aways_dict[f'{rivals[1]}|{date}'] = index\n",
    "        \n",
    "    # generate team_dates_dict['PITT'] --> a list of dates when the team played\n",
    "\n",
    "    team_dates_dict = {}\n",
    "    for index, r in games.iterrows():\n",
    "        date = r['date']\n",
    "        rivals = r['rivalry'].split('-')\n",
    "        for t in range(0, 2):\n",
    "            homeaway = 'home' if t == 0 else 'away'\n",
    "            entry = (date, rivals[1-t], homeaway)\n",
    "            if rivals[t] not in team_dates_dict.keys():\n",
    "                team_dates_dict[rivals[t]] = [entry]\n",
    "            else:\n",
    "                team_dates_dict[rivals[t]].append(entry)\n",
    "                \n",
    "if not definition_only:\n",
    "    Part_III()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10becb0c",
   "metadata": {},
   "source": [
    "# Part IV -- ESPN QBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a41eba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Part_IV():\n",
    "    \n",
    "    global espn_qbr_2006_2020, espn_qbr_2021, espn_qbr_2022\n",
    "    \n",
    "    espn_qbr_2006_2020 = pd.read_csv('data/espn/espn-qbr-nfl-weekly-2006-2020.csv')\n",
    "    espn_qbr_2021 = pd.read_csv('data/espn/espn-qbr-nfl-weekly-2021.csv')\n",
    "    espn_qbr_2022 = pd.read_csv('data/espn/espn-qbr-nfl-weekly-2022.csv')\n",
    "    espn_qbr_2021 = espn_qbr_2021.drop(['Unnamed: 0'], axis=1)\n",
    "    espn_qbr_2022 = espn_qbr_2022.drop(['Unnamed: 0'], axis=1)\n",
    "    espn_qbr_2006_2020['team_abb'].replace(abbrev_to_canon_dict, inplace=True)\n",
    "    espn_qbr_2006_2020['opp_abb'].replace(abbrev_to_canon_dict, inplace=True)\n",
    "    espn_qbr_2021['team_abb'].replace(abbrev_to_canon_dict, inplace=True)\n",
    "    espn_qbr_2021['opp_abb'].replace(abbrev_to_canon_dict, inplace=True)\n",
    "    espn_qbr_2022['team_abb'].replace(abbrev_to_canon_dict, inplace=True)\n",
    "    espn_qbr_2022['opp_abb'].replace(abbrev_to_canon_dict, inplace=True)\n",
    "    \n",
    "if not definition_only:\n",
    "    Part_IV()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6318caa",
   "metadata": {},
   "source": [
    "# Part V -- Calender Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49eb72e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2007-02-04', 'season': 2006, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 39115}\n",
      "{'date': '2008-02-03', 'season': 2007, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 39479}\n",
      "{'date': '2009-02-01', 'season': 2008, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 39843}\n",
      "{'date': '2010-02-07', 'season': 2009, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 40214}\n",
      "{'date': '2011-02-06', 'season': 2010, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 40578}\n",
      "{'date': '2012-02-05', 'season': 2011, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 40942}\n",
      "{'date': '2013-02-03', 'season': 2012, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 41306}\n",
      "{'date': '2014-02-02', 'season': 2013, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 41670}\n",
      "{'date': '2015-02-01', 'season': 2014, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 42034}\n",
      "{'date': '2016-02-07', 'season': 2015, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 42405}\n",
      "{'date': '2017-02-05', 'season': 2016, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 42769}\n",
      "{'date': '2018-02-04', 'season': 2017, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 43133}\n",
      "{'date': '2019-02-03', 'season': 2018, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 43497}\n",
      "{'date': '2020-02-02', 'season': 2019, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 43861}\n",
      "{'date': '2021-02-07', 'season': 2020, 'week': 22, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 44232}\n",
      "{'date': '2022-02-13', 'season': 2021, 'week': 23, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 44603}\n",
      "{'date': '2023-02-12', 'season': 2022, 'week': 23, 'weekday': 6, 'weekday-name': 'Sunday', 'week-name': 'Super Bowl', 'regular': False, 'absolute': 44967}\n"
     ]
    }
   ],
   "source": [
    "season_kickoffs = {}\n",
    "season_first_last = pd.read_csv('data/hardy/season_first_last.csv')\n",
    "for index, r in season_first_last.iterrows():\n",
    "    first_day = datetime.strptime(r['first'], \"%Y-%m-%d\")\n",
    "    last_day = datetime.strptime(r['last'], \"%Y-%m-%d\")  # superbowl\n",
    "    delta_days = last_day - first_day + timedelta(days=1)\n",
    "    season_kickoffs[first_day.year] = first_day\n",
    "\n",
    "def parse_date(date_text):\n",
    "    date = datetime.strptime(date_text, \"%Y-%m-%d\")\n",
    "    season = date.year\n",
    "    if date.month < 6:\n",
    "        season -= 1  # NFL season\n",
    "    kickoff = season_kickoffs[season]\n",
    "    delta_days = (date - kickoff).days\n",
    "    week = 1 + (delta_days // 7)\n",
    "    regular_week_count = (17 + 1) if season >= 2021 else (16 + 1)\n",
    "        # 17 games since 2021\n",
    "        \n",
    "    days_since_1900 = (date - datetime(1900, 1, 1)).days\n",
    "    regular = week >= 1 and week <= regular_week_count\n",
    "    if regular:\n",
    "        week_name = f\"Week {week}\"\n",
    "    else:\n",
    "        if week - regular_week_count == 1:\n",
    "            week_name = 'Wild Card'\n",
    "        elif week - regular_week_count == 2:\n",
    "            week_name = 'Divisional Round'\n",
    "        elif week - regular_week_count == 3:\n",
    "            week_name = 'Conference Championship'\n",
    "        elif week - regular_week_count == 5:\n",
    "            week_name = 'Super Bowl'\n",
    "        else:\n",
    "            week_name = 'Unknown'\n",
    "    \n",
    "    return {\n",
    "        'date': date_text,\n",
    "        'season': season,\n",
    "        'week': week,\n",
    "        'weekday': date.weekday(),\n",
    "        'weekday-name': date.strftime(\"%A\"),\n",
    "        'week-name': week_name,\n",
    "        'regular': regular,  # regular season\n",
    "        'absolute': days_since_1900,\n",
    "    }\n",
    "\n",
    "season_first_last = pd.read_csv('data/hardy/season_first_last.csv')\n",
    "for index, r in season_first_last.iterrows():\n",
    "    superbowl = parse_date(r['last'])  # superbowl\n",
    "    print(superbowl)\n",
    "    \n",
    "def Part_V():\n",
    "    ()  # we should always do this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad06954a",
   "metadata": {},
   "source": [
    "# Part VI -- Fixing ESPN QBR\n",
    "\n",
    "The team associated with the QB is misattributed (it was the current team of the player,\n",
    "not the team of the player at the time of the game), so we'll reverse-engineer the\n",
    "actual team based on the opposing team and the date of the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a08f3a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the team associated with the QB is misattributed (it was the current team of the player,\n",
    "# not the team of the player at the time of the game), so we'll reverse-engineer the\n",
    "# actual team based on the opposing team and the date of the game\n",
    "\n",
    "def fix_espn(espn_qbr):\n",
    "    if 'name_display' in espn_qbr.keys():\n",
    "        name_key = 'name_display'  # 2021, 2022\n",
    "    else:\n",
    "        name_key = 'name'  # 2006-2020\n",
    "    for index, r in espn_qbr.iterrows():\n",
    "        name = r[name_key]\n",
    "        opp = r['opp_abb']\n",
    "        team = r['team_abb']\n",
    "        season = r['season']\n",
    "        week_text = r['week_text']\n",
    "        actual_team = None\n",
    "        for (date, opp, homeaway) in team_dates_dict[opp]:\n",
    "            parsed = parse_date(date)\n",
    "            if parsed['season'] == season and parsed['week-name'] == week_text:\n",
    "                assert(actual_team == None)\n",
    "                actual_team = opp\n",
    "\n",
    "        if actual_team == None:\n",
    "            print(f'Unable to find {name}, {opp}, {team}, {r[\"season\"]}, {r[\"week_text\"]} (SKIPPED)')\n",
    "            continue  # this happens because of the result of the three missing games\n",
    "\n",
    "        assert(actual_team != None)\n",
    "        if actual_team != team:\n",
    "            espn_qbr.at[index, 'team_abb'] = actual_team\n",
    "            print(f'{name} @{season}/{week_text} {team} (mistake) --> {actual_team} (correction)')\n",
    "    return espn_qbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd9884e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_qbr_dict(verbose=False):\n",
    "    espn_qbr_dict = {}\n",
    "    for espn_qbr in [espn_qbr_2006_2020, espn_qbr_2021, espn_qbr_2022]:\n",
    "    # for espn_qbr in [espn_qbr_2021]:\n",
    "        grouped = espn_qbr.groupby(['season', 'season_type', 'game_week', 'week_text', 'team_abb'])\n",
    "        for (season, season_type, game_week, week_text, team), group in grouped:\n",
    "            mean_qbr_total = group['qbr_total'].mean()\n",
    "            count_qbr_total = group['qbr_total'].count()\n",
    "            matched_parsed = None\n",
    "            for team_date in team_dates_dict[team]:\n",
    "                parsed = parse_date(team_date[0])\n",
    "                if parsed['season'] == season and parsed['week-name'] == week_text:\n",
    "                    matched_parsed = parsed\n",
    "            if matched_parsed == None:\n",
    "                print(f'{team}: failed to match {season}, {week_text}')\n",
    "                continue\n",
    "            key = f'{team}|{matched_parsed[\"date\"]}'\n",
    "            espn_qbr_dict[key] = mean_qbr_total\n",
    "\n",
    "            if verbose and count_qbr_total > 1:\n",
    "                print(f\"{team} {week_text} of {season}: QBR = {mean_qbr_total} ({count_qbr_total})\")\n",
    "    return espn_qbr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a799e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find Todd Collins, SF, WSH, 2007, Week 17 (SKIPPED)\n",
      "Unable to find Tony Romo, DAL, DAL, 2007, Week 17 (SKIPPED)\n",
      "Trent Edwards @2010/Week 1 JAX (mistake) --> BUF (correction)\n",
      "Trent Edwards @2010/Week 2 JAX (mistake) --> BUF (correction)\n",
      "Unable to find Ben Roethlisberger, NO, PIT, 2010, Week 16 (SKIPPED)\n",
      "Unable to find Jimmy Clausen, CLE, CAR, 2010, Week 16 (SKIPPED)\n",
      "Kyle Orton @2011/Week 1 KC (mistake) --> DEN (correction)\n",
      "Kyle Orton @2011/Week 2 KC (mistake) --> DEN (correction)\n",
      "Kyle Orton @2011/Week 3 KC (mistake) --> DEN (correction)\n",
      "Kyle Orton @2011/Week 4 KC (mistake) --> DEN (correction)\n",
      "Unable to find Josh Freeman, TB, TB, 2011, Week 17 (SKIPPED)\n",
      "Brian Hoyer @2012/Week 16 PIT (mistake) --> ARI (correction)\n",
      "Brian Hoyer @2012/Week 17 PIT (mistake) --> ARI (correction)\n",
      "Josh Freeman @2013/Week 7 TB (mistake) --> MIN (correction)\n",
      "Matt Flynn @2013/Week 12 LV (mistake) --> GB (correction)\n",
      "Matt Flynn @2013/Week 13 LV (mistake) --> GB (correction)\n",
      "Matt Flynn @2013/Week 14 LV (mistake) --> GB (correction)\n",
      "Matt Flynn @2013/Week 15 LV (mistake) --> GB (correction)\n",
      "Matt Flynn @2013/Week 16 LV (mistake) --> GB (correction)\n",
      "Jimmy Clausen @2015/Week 2 BAL (mistake) --> CHI (correction)\n",
      "Brandon Weeden @2015/Week 3 HOU (mistake) --> DAL (correction)\n",
      "Jimmy Clausen @2015/Week 3 BAL (mistake) --> CHI (correction)\n",
      "Brandon Weeden @2015/Week 4 HOU (mistake) --> DAL (correction)\n",
      "Brandon Weeden @2015/Week 5 HOU (mistake) --> DAL (correction)\n",
      "Ryan Mallett @2015/Week 16 HOU (mistake) --> BAL (correction)\n",
      "Ryan Mallett @2015/Week 17 HOU (mistake) --> BAL (correction)\n",
      "Charlie Whitehurst @2016/Week 5 IND (mistake) --> CLE (correction)\n",
      "Kevin Hogan @2016/Week 7 KC (mistake) --> CLE (correction)\n",
      "Matt Barkley @2016/Week 12 ARI (mistake) --> CHI (correction)\n",
      "Matt Barkley @2016/Week 13 ARI (mistake) --> CHI (correction)\n",
      "Matt Barkley @2016/Week 14 ARI (mistake) --> CHI (correction)\n",
      "Matt Barkley @2016/Week 15 ARI (mistake) --> CHI (correction)\n",
      "Matt Barkley @2016/Week 16 ARI (mistake) --> CHI (correction)\n",
      "Mark Sanchez @2016/Week 17 DEN (mistake) --> DAL (correction)\n",
      "Nathan Peterman @2018/Week 1 LV (mistake) --> BUF (correction)\n",
      "Nathan Peterman @2018/Week 9 LV (mistake) --> BUF (correction)\n",
      "Matt Barkley @2018/Week 10 CIN (mistake) --> BUF (correction)\n",
      "Ryan Fitzpatrick @2020/Week 1 WSH (mistake) --> MIA (correction)\n",
      "Mitchell Trubisky @2020/Week 1 BUF (mistake) --> CHI (correction)\n",
      "Matthew Stafford @2020/Week 1 LAR (mistake) --> DET (correction)\n",
      "Dwayne Haskins Jr. @2020/Week 1 PIT (mistake) --> WSH (correction)\n",
      "Jared Goff @2020/Week 1 DET (mistake) --> LAR (correction)\n",
      "Tyrod Taylor @2020/Week 1 HOU (mistake) --> LAC (correction)\n",
      "Carson Wentz @2020/Week 1 IND (mistake) --> PHI (correction)\n",
      "Sam Darnold @2020/Week 1 CAR (mistake) --> NYJ (correction)\n",
      "Jared Goff @2020/Week 2 DET (mistake) --> LAR (correction)\n",
      "Sam Darnold @2020/Week 2 CAR (mistake) --> NYJ (correction)\n",
      "Ryan Fitzpatrick @2020/Week 2 WSH (mistake) --> MIA (correction)\n",
      "Matthew Stafford @2020/Week 2 LAR (mistake) --> DET (correction)\n",
      "Mitchell Trubisky @2020/Week 2 BUF (mistake) --> CHI (correction)\n",
      "Carson Wentz @2020/Week 2 IND (mistake) --> PHI (correction)\n",
      "Dwayne Haskins Jr. @2020/Week 2 PIT (mistake) --> WSH (correction)\n",
      "Ryan Fitzpatrick @2020/Week 3 WSH (mistake) --> MIA (correction)\n",
      "Jared Goff @2020/Week 3 DET (mistake) --> LAR (correction)\n",
      "Matthew Stafford @2020/Week 3 LAR (mistake) --> DET (correction)\n",
      "Mitchell Trubisky @2020/Week 3 BUF (mistake) --> CHI (correction)\n",
      "Carson Wentz @2020/Week 3 IND (mistake) --> PHI (correction)\n",
      "Dwayne Haskins Jr. @2020/Week 3 PIT (mistake) --> WSH (correction)\n",
      "Sam Darnold @2020/Week 3 CAR (mistake) --> NYJ (correction)\n",
      "Matthew Stafford @2020/Week 4 LAR (mistake) --> DET (correction)\n",
      "Carson Wentz @2020/Week 4 IND (mistake) --> PHI (correction)\n",
      "Sam Darnold @2020/Week 4 CAR (mistake) --> NYJ (correction)\n",
      "C.J. Beathard @2020/Week 4 JAX (mistake) --> SF (correction)\n",
      "Ryan Fitzpatrick @2020/Week 4 WSH (mistake) --> MIA (correction)\n",
      "Jared Goff @2020/Week 4 DET (mistake) --> LAR (correction)\n",
      "Dwayne Haskins Jr. @2020/Week 4 PIT (mistake) --> WSH (correction)\n",
      "Ryan Fitzpatrick @2020/Week 5 WSH (mistake) --> MIA (correction)\n",
      "Jared Goff @2020/Week 5 DET (mistake) --> LAR (correction)\n",
      "Carson Wentz @2020/Week 5 IND (mistake) --> PHI (correction)\n",
      "Joe Flacco @2020/Week 5 PHI (mistake) --> NYJ (correction)\n",
      "C.J. Beathard @2020/Week 5 JAX (mistake) --> SF (correction)\n",
      "Matthew Stafford @2020/Week 6 LAR (mistake) --> DET (correction)\n",
      "Jared Goff @2020/Week 6 DET (mistake) --> LAR (correction)\n",
      "Ryan Fitzpatrick @2020/Week 6 WSH (mistake) --> MIA (correction)\n",
      "Carson Wentz @2020/Week 6 IND (mistake) --> PHI (correction)\n",
      "Andy Dalton @2020/Week 6 CHI (mistake) --> DAL (correction)\n",
      "Joe Flacco @2020/Week 6 PHI (mistake) --> NYJ (correction)\n",
      "Matthew Stafford @2020/Week 7 LAR (mistake) --> DET (correction)\n",
      "Jared Goff @2020/Week 7 DET (mistake) --> LAR (correction)\n",
      "Carson Wentz @2020/Week 7 IND (mistake) --> PHI (correction)\n",
      "Sam Darnold @2020/Week 7 CAR (mistake) --> NYJ (correction)\n",
      "Andy Dalton @2020/Week 7 CHI (mistake) --> DAL (correction)\n",
      "Sam Darnold @2020/Week 8 CAR (mistake) --> NYJ (correction)\n",
      "Carson Wentz @2020/Week 8 IND (mistake) --> PHI (correction)\n",
      "Matthew Stafford @2020/Week 8 LAR (mistake) --> DET (correction)\n",
      "Jared Goff @2020/Week 8 DET (mistake) --> LAR (correction)\n",
      "Joe Flacco @2020/Week 9 PHI (mistake) --> NYJ (correction)\n",
      "Matthew Stafford @2020/Week 9 LAR (mistake) --> DET (correction)\n",
      "Matthew Stafford @2020/Week 10 LAR (mistake) --> DET (correction)\n",
      "Jared Goff @2020/Week 10 DET (mistake) --> LAR (correction)\n",
      "Carson Wentz @2020/Week 10 IND (mistake) --> PHI (correction)\n",
      "Jared Goff @2020/Week 11 DET (mistake) --> LAR (correction)\n",
      "Andy Dalton @2020/Week 11 CHI (mistake) --> DAL (correction)\n",
      "Ryan Fitzpatrick @2020/Week 11 WSH (mistake) --> MIA (correction)\n",
      "Joe Flacco @2020/Week 11 PHI (mistake) --> NYJ (correction)\n",
      "Matthew Stafford @2020/Week 11 LAR (mistake) --> DET (correction)\n",
      "Carson Wentz @2020/Week 11 IND (mistake) --> PHI (correction)\n",
      "Andy Dalton @2020/Week 12 CHI (mistake) --> DAL (correction)\n",
      "Ryan Fitzpatrick @2020/Week 12 WSH (mistake) --> MIA (correction)\n",
      "Carson Wentz @2020/Week 12 IND (mistake) --> PHI (correction)\n",
      "Mike Glennon @2020/Week 12 NYG (mistake) --> JAX (correction)\n",
      "Mitchell Trubisky @2020/Week 12 BUF (mistake) --> CHI (correction)\n",
      "Matthew Stafford @2020/Week 12 LAR (mistake) --> DET (correction)\n",
      "Sam Darnold @2020/Week 12 CAR (mistake) --> NYJ (correction)\n",
      "Jared Goff @2020/Week 12 DET (mistake) --> LAR (correction)\n",
      "Jared Goff @2020/Week 13 DET (mistake) --> LAR (correction)\n",
      "Matthew Stafford @2020/Week 13 LAR (mistake) --> DET (correction)\n",
      "Andy Dalton @2020/Week 13 CHI (mistake) --> DAL (correction)\n",
      "Mitchell Trubisky @2020/Week 13 BUF (mistake) --> CHI (correction)\n",
      "Mike Glennon @2020/Week 13 NYG (mistake) --> JAX (correction)\n",
      "Colt McCoy @2020/Week 13 ARI (mistake) --> NYG (correction)\n",
      "Carson Wentz @2020/Week 13 IND (mistake) --> PHI (correction)\n",
      "Sam Darnold @2020/Week 13 CAR (mistake) --> NYJ (correction)\n",
      "Matthew Stafford @2020/Week 14 LAR (mistake) --> DET (correction)\n",
      "Andy Dalton @2020/Week 14 CHI (mistake) --> DAL (correction)\n",
      "Mitchell Trubisky @2020/Week 14 BUF (mistake) --> CHI (correction)\n",
      "Jared Goff @2020/Week 14 DET (mistake) --> LAR (correction)\n",
      "Sam Darnold @2020/Week 14 CAR (mistake) --> NYJ (correction)\n",
      "Mike Glennon @2020/Week 14 NYG (mistake) --> JAX (correction)\n",
      "Matthew Stafford @2020/Week 15 LAR (mistake) --> DET (correction)\n",
      "Sam Darnold @2020/Week 15 CAR (mistake) --> NYJ (correction)\n",
      "Ryan Finley @2020/Week 15 HOU (mistake) --> CIN (correction)\n",
      "Mitchell Trubisky @2020/Week 15 BUF (mistake) --> CHI (correction)\n",
      "Dwayne Haskins Jr. @2020/Week 15 PIT (mistake) --> WSH (correction)\n",
      "Colt McCoy @2020/Week 15 ARI (mistake) --> NYG (correction)\n",
      "Andy Dalton @2020/Week 15 CHI (mistake) --> DAL (correction)\n",
      "Jared Goff @2020/Week 15 DET (mistake) --> LAR (correction)\n",
      "Andy Dalton @2020/Week 16 CHI (mistake) --> DAL (correction)\n",
      "Mitchell Trubisky @2020/Week 16 BUF (mistake) --> CHI (correction)\n",
      "Mike Glennon @2020/Week 16 NYG (mistake) --> JAX (correction)\n",
      "Jared Goff @2020/Week 16 DET (mistake) --> LAR (correction)\n",
      "Sam Darnold @2020/Week 16 CAR (mistake) --> NYJ (correction)\n",
      "C.J. Beathard @2020/Week 16 JAX (mistake) --> SF (correction)\n",
      "Chase Daniel @2020/Week 16 LAC (mistake) --> DET (correction)\n",
      "Dwayne Haskins Jr. @2020/Week 16 PIT (mistake) --> WSH (correction)\n",
      "Mitchell Trubisky @2020/Week 17 BUF (mistake) --> CHI (correction)\n",
      "Matthew Stafford @2020/Week 17 LAR (mistake) --> DET (correction)\n",
      "C.J. Beathard @2020/Week 17 JAX (mistake) --> SF (correction)\n",
      "Andy Dalton @2020/Week 17 CHI (mistake) --> DAL (correction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mike Glennon @2020/Week 17 NYG (mistake) --> JAX (correction)\n",
      "Sam Darnold @2020/Week 17 CAR (mistake) --> NYJ (correction)\n",
      "Jared Goff @2020/Wild Card DET (mistake) --> LAR (correction)\n",
      "Mitchell Trubisky @2020/Wild Card BUF (mistake) --> CHI (correction)\n",
      "Jared Goff @2020/Divisional Round DET (mistake) --> LAR (correction)\n",
      "Josh Johnson @2021/Week 9 BAL (mistake) --> NYJ (correction)\n",
      "Marcus Mariota @2022/Week 1 PHI (mistake) --> ATL (correction)\n",
      "Baker Mayfield @2022/Week 1 TB (mistake) --> CAR (correction)\n",
      "Jacoby Brissett @2022/Week 1 WSH (mistake) --> CLE (correction)\n",
      "Derek Carr @2022/Week 1 NO (mistake) --> LV (correction)\n",
      "Aaron Rodgers @2022/Week 1 NYJ (mistake) --> GB (correction)\n",
      "Jacoby Brissett @2022/Week 2 WSH (mistake) --> CLE (correction)\n",
      "Jimmy Garoppolo @2022/Week 2 LV (mistake) --> SF (correction)\n",
      "Derek Carr @2022/Week 2 NO (mistake) --> LV (correction)\n",
      "Marcus Mariota @2022/Week 2 PHI (mistake) --> ATL (correction)\n",
      "Aaron Rodgers @2022/Week 2 NYJ (mistake) --> GB (correction)\n",
      "Baker Mayfield @2022/Week 2 TB (mistake) --> CAR (correction)\n",
      "Jacoby Brissett @2022/Week 3 WSH (mistake) --> CLE (correction)\n",
      "Derek Carr @2022/Week 3 NO (mistake) --> LV (correction)\n",
      "Aaron Rodgers @2022/Week 3 NYJ (mistake) --> GB (correction)\n",
      "Marcus Mariota @2022/Week 3 PHI (mistake) --> ATL (correction)\n",
      "Jimmy Garoppolo @2022/Week 3 LV (mistake) --> SF (correction)\n",
      "Baker Mayfield @2022/Week 3 TB (mistake) --> CAR (correction)\n",
      "Derek Carr @2022/Week 4 NO (mistake) --> LV (correction)\n",
      "Andy Dalton @2022/Week 4 CAR (mistake) --> NO (correction)\n",
      "Jacoby Brissett @2022/Week 4 WSH (mistake) --> CLE (correction)\n",
      "Aaron Rodgers @2022/Week 4 NYJ (mistake) --> GB (correction)\n",
      "Jimmy Garoppolo @2022/Week 4 LV (mistake) --> SF (correction)\n",
      "Marcus Mariota @2022/Week 4 PHI (mistake) --> ATL (correction)\n",
      "Baker Mayfield @2022/Week 4 TB (mistake) --> CAR (correction)\n",
      "Jacoby Brissett @2022/Week 5 WSH (mistake) --> CLE (correction)\n",
      "Derek Carr @2022/Week 5 NO (mistake) --> LV (correction)\n",
      "Andy Dalton @2022/Week 5 CAR (mistake) --> NO (correction)\n",
      "Marcus Mariota @2022/Week 5 PHI (mistake) --> ATL (correction)\n",
      "Jimmy Garoppolo @2022/Week 5 LV (mistake) --> SF (correction)\n",
      "Aaron Rodgers @2022/Week 5 NYJ (mistake) --> GB (correction)\n",
      "Baker Mayfield @2022/Week 5 TB (mistake) --> CAR (correction)\n",
      "Marcus Mariota @2022/Week 6 PHI (mistake) --> ATL (correction)\n",
      "Jimmy Garoppolo @2022/Week 6 LV (mistake) --> SF (correction)\n",
      "Andy Dalton @2022/Week 6 CAR (mistake) --> NO (correction)\n",
      "Jacoby Brissett @2022/Week 6 WSH (mistake) --> CLE (correction)\n",
      "Aaron Rodgers @2022/Week 6 NYJ (mistake) --> GB (correction)\n",
      "Derek Carr @2022/Week 7 NO (mistake) --> LV (correction)\n",
      "PJ Walker @2022/Week 7 CHI (mistake) --> CAR (correction)\n",
      "Andy Dalton @2022/Week 7 CAR (mistake) --> NO (correction)\n",
      "Jacoby Brissett @2022/Week 7 WSH (mistake) --> CLE (correction)\n",
      "Marcus Mariota @2022/Week 7 PHI (mistake) --> ATL (correction)\n",
      "Aaron Rodgers @2022/Week 7 NYJ (mistake) --> GB (correction)\n",
      "Jimmy Garoppolo @2022/Week 7 LV (mistake) --> SF (correction)\n",
      "Taylor Heinicke @2022/Week 7 ATL (mistake) --> WSH (correction)\n",
      "Brett Rypien @2022/Week 7 LAR (mistake) --> DEN (correction)\n",
      "Jacoby Brissett @2022/Week 8 WSH (mistake) --> CLE (correction)\n",
      "Jimmy Garoppolo @2022/Week 8 LV (mistake) --> SF (correction)\n",
      "Andy Dalton @2022/Week 8 CAR (mistake) --> NO (correction)\n",
      "Marcus Mariota @2022/Week 8 PHI (mistake) --> ATL (correction)\n",
      "Taylor Heinicke @2022/Week 8 ATL (mistake) --> WSH (correction)\n",
      "PJ Walker @2022/Week 8 CHI (mistake) --> CAR (correction)\n",
      "Aaron Rodgers @2022/Week 8 NYJ (mistake) --> GB (correction)\n",
      "Derek Carr @2022/Week 8 NO (mistake) --> LV (correction)\n",
      "Baker Mayfield @2022/Week 9 TB (mistake) --> CAR (correction)\n",
      "Derek Carr @2022/Week 9 NO (mistake) --> LV (correction)\n",
      "Marcus Mariota @2022/Week 9 PHI (mistake) --> ATL (correction)\n",
      "Taylor Heinicke @2022/Week 9 ATL (mistake) --> WSH (correction)\n",
      "Aaron Rodgers @2022/Week 9 NYJ (mistake) --> GB (correction)\n",
      "Andy Dalton @2022/Week 9 CAR (mistake) --> NO (correction)\n",
      "Aaron Rodgers @2022/Week 10 NYJ (mistake) --> GB (correction)\n",
      "Jacoby Brissett @2022/Week 10 WSH (mistake) --> CLE (correction)\n",
      "Jimmy Garoppolo @2022/Week 10 LV (mistake) --> SF (correction)\n",
      "Taylor Heinicke @2022/Week 10 ATL (mistake) --> WSH (correction)\n",
      "Marcus Mariota @2022/Week 10 PHI (mistake) --> ATL (correction)\n",
      "Derek Carr @2022/Week 10 NO (mistake) --> LV (correction)\n",
      "Andy Dalton @2022/Week 10 CAR (mistake) --> NO (correction)\n",
      "John Wolford @2022/Week 10 TB (mistake) --> LAR (correction)\n",
      "PJ Walker @2022/Week 10 CHI (mistake) --> CAR (correction)\n",
      "Andy Dalton @2022/Week 11 CAR (mistake) --> NO (correction)\n",
      "Jimmy Garoppolo @2022/Week 11 LV (mistake) --> SF (correction)\n",
      "Derek Carr @2022/Week 11 NO (mistake) --> LV (correction)\n",
      "Jacoby Brissett @2022/Week 11 WSH (mistake) --> CLE (correction)\n",
      "Taylor Heinicke @2022/Week 11 ATL (mistake) --> WSH (correction)\n",
      "Aaron Rodgers @2022/Week 11 NYJ (mistake) --> GB (correction)\n",
      "Marcus Mariota @2022/Week 11 PHI (mistake) --> ATL (correction)\n",
      "Baker Mayfield @2022/Week 11 TB (mistake) --> CAR (correction)\n",
      "Mike White @2022/Week 12 MIA (mistake) --> NYJ (correction)\n",
      "Jimmy Garoppolo @2022/Week 12 LV (mistake) --> SF (correction)\n",
      "Derek Carr @2022/Week 12 NO (mistake) --> LV (correction)\n",
      "Sam Darnold @2022/Week 12 SF (mistake) --> CAR (correction)\n",
      "Marcus Mariota @2022/Week 12 PHI (mistake) --> ATL (correction)\n",
      "Taylor Heinicke @2022/Week 12 ATL (mistake) --> WSH (correction)\n",
      "Andy Dalton @2022/Week 12 CAR (mistake) --> NO (correction)\n",
      "Jacoby Brissett @2022/Week 12 WSH (mistake) --> CLE (correction)\n",
      "Aaron Rodgers @2022/Week 12 NYJ (mistake) --> GB (correction)\n",
      "Trevor Siemian @2022/Week 12 CIN (mistake) --> CHI (correction)\n",
      "Kyle Allen @2022/Week 12 BUF (mistake) --> HOU (correction)\n",
      "Andy Dalton @2022/Week 13 CAR (mistake) --> NO (correction)\n",
      "Derek Carr @2022/Week 13 NO (mistake) --> LV (correction)\n",
      "Aaron Rodgers @2022/Week 13 NYJ (mistake) --> GB (correction)\n",
      "Marcus Mariota @2022/Week 13 PHI (mistake) --> ATL (correction)\n",
      "Taylor Heinicke @2022/Week 13 ATL (mistake) --> WSH (correction)\n",
      "John Wolford @2022/Week 13 TB (mistake) --> LAR (correction)\n",
      "Mike White @2022/Week 13 MIA (mistake) --> NYJ (correction)\n",
      "Kyle Allen @2022/Week 13 BUF (mistake) --> HOU (correction)\n",
      "Baker Mayfield @2022/Week 14 TB (mistake) --> LAR (correction)\n",
      "Mike White @2022/Week 14 MIA (mistake) --> NYJ (correction)\n",
      "Derek Carr @2022/Week 14 NO (mistake) --> LV (correction)\n",
      "Sam Darnold @2022/Week 14 SF (mistake) --> CAR (correction)\n",
      "Andy Dalton @2022/Week 15 CAR (mistake) --> NO (correction)\n",
      "Sam Darnold @2022/Week 15 SF (mistake) --> CAR (correction)\n",
      "Derek Carr @2022/Week 15 NO (mistake) --> LV (correction)\n",
      "Aaron Rodgers @2022/Week 15 NYJ (mistake) --> GB (correction)\n",
      "Taylor Heinicke @2022/Week 15 ATL (mistake) --> WSH (correction)\n",
      "Brett Rypien @2022/Week 15 LAR (mistake) --> DEN (correction)\n",
      "Baker Mayfield @2022/Week 15 TB (mistake) --> LAR (correction)\n",
      "Baker Mayfield @2022/Week 16 TB (mistake) --> LAR (correction)\n",
      "Sam Darnold @2022/Week 16 SF (mistake) --> CAR (correction)\n",
      "Taylor Heinicke @2022/Week 16 ATL (mistake) --> WSH (correction)\n",
      "Gardner Minshew @2022/Week 16 IND (mistake) --> PHI (correction)\n",
      "Aaron Rodgers @2022/Week 16 NYJ (mistake) --> GB (correction)\n",
      "Derek Carr @2022/Week 16 NO (mistake) --> LV (correction)\n",
      "Trace McSorley @2022/Week 16 NE (mistake) --> ARI (correction)\n",
      "Jarrett Stidham @2022/Week 17 DEN (mistake) --> LV (correction)\n",
      "Sam Darnold @2022/Week 17 SF (mistake) --> CAR (correction)\n",
      "Aaron Rodgers @2022/Week 17 NYJ (mistake) --> GB (correction)\n",
      "Andy Dalton @2022/Week 17 CAR (mistake) --> NO (correction)\n",
      "Joshua Dobbs @2022/Week 17 CLE (mistake) --> TEN (correction)\n",
      "Baker Mayfield @2022/Week 17 TB (mistake) --> LAR (correction)\n",
      "Mike White @2022/Week 17 MIA (mistake) --> NYJ (correction)\n",
      "Gardner Minshew @2022/Week 17 IND (mistake) --> PHI (correction)\n",
      "DAL: failed to match 2007, Week 17\n",
      "WSH: failed to match 2007, Week 17\n",
      "CAR: failed to match 2010, Week 16\n",
      "PIT: failed to match 2010, Week 16\n",
      "TB: failed to match 2011, Week 17\n"
     ]
    }
   ],
   "source": [
    "def Part_VI():\n",
    "    \n",
    "    global espn_qbr_2006_2020, espn_qbr_2021, espn_qbr_2022, espn_qbr_dict\n",
    "    \n",
    "    fix_espn(espn_qbr_2006_2020)\n",
    "    fix_espn(espn_qbr_2021)\n",
    "    fix_espn(espn_qbr_2022)\n",
    "    espn_qbr_dict = make_qbr_dict()\n",
    "    \n",
    "if not definition_only:\n",
    "    Part_VI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e0ba23",
   "metadata": {},
   "source": [
    "# Part VII -- Five Thirty Eight ELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a765b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Part_VII():\n",
    "    \n",
    "    global elo_dict\n",
    "    \n",
    "    elo_dict = {}\n",
    "    for index, r in fivethirtyeight.iterrows():\n",
    "        home = r['team1']\n",
    "        away = r['team2']\n",
    "        date = r['date']\n",
    "        for homeQ in [True, False]:\n",
    "            homeaway = '1' if homeQ else '2'\n",
    "            awayhome = '2' if homeQ else '1'\n",
    "            home = r[f'team{homeaway}']\n",
    "            key = f'{home}|{date}'\n",
    "            elo_dict[key] = {\n",
    "                'elo-post': r[f'elo{homeaway}_post'],\n",
    "                'qb-elo-post': r[f'qbelo{homeaway}_post'],\n",
    "                    # after the game (note, we should not use the -pre value before\n",
    "                    # the game because it leaks details about who played the game\n",
    "            }\n",
    "            \n",
    "if not definition_only:\n",
    "    Part_VII()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fad8ca",
   "metadata": {},
   "source": [
    "# Part VIII -- Compute TwoHalves\n",
    "\n",
    "Note that a game is made of two teams (obviously), called a rivalry, and the statistics are of the form \"total_yards_home\" and \"total_yards_away\". This is to separate the statistics into another dataframe with (roughly) twice the number of rows but half the number of columns. I call it \"twohalves\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abdd42de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows (VIII): 100%|█████████████| 4573/4573 [00:01<00:00, 2708.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing 552 QBRs (6.04%)\n",
      "PIT has played a total of 290 games\n",
      "MIA has played a total of 277 games\n",
      "ARI has played a total of 284 games\n",
      "SF has played a total of 291 games\n",
      "CAR has played a total of 281 games\n",
      "ATL has played a total of 283 games\n",
      "CLE has played a total of 276 games\n",
      "NO has played a total of 291 games\n",
      "DET has played a total of 277 games\n",
      "SEA has played a total of 297 games\n",
      "GB has played a total of 297 games\n",
      "CHI has played a total of 281 games\n",
      "HOU has played a total of 284 games\n",
      "PHI has played a total of 292 games\n",
      "JAX has played a total of 281 games\n",
      "DAL has played a total of 285 games\n",
      "KC has played a total of 295 games\n",
      "CIN has played a total of 286 games\n",
      "LAR has played a total of 284 games\n",
      "DEN has played a total of 284 games\n",
      "NE has played a total of 305 games\n",
      "BUF has played a total of 282 games\n",
      "NYG has played a total of 287 games\n",
      "IND has played a total of 293 games\n",
      "TB has played a total of 281 games\n",
      "BAL has played a total of 295 games\n",
      "TEN has played a total of 283 games\n",
      "NYJ has played a total of 281 games\n",
      "LV has played a total of 276 games\n",
      "LAC has played a total of 286 games\n",
      "WSH has played a total of 277 games\n",
      "MIN has played a total of 284 games\n"
     ]
    }
   ],
   "source": [
    "def Part_VIII():\n",
    "    \n",
    "    global twohalves_dict\n",
    "    \n",
    "    rows = []\n",
    "    missing_qbr_count = 0\n",
    "    for index, r in tqdm(team_stat.iterrows(), total=len(team_stat), desc='Processing rows (VIII)'):\n",
    "        row_home = None\n",
    "        row_away = None\n",
    "        for homeQ in [True, False]:\n",
    "            date = r['date']\n",
    "            homeaway = 'home' if homeQ else 'away'\n",
    "            awayhome = 'away' if homeQ else 'home'\n",
    "            team = r[homeaway]\n",
    "            opponent = r[awayhome]\n",
    "            rivalry = f'{r[homeaway]}-{r[awayhome]}'\n",
    "            first_downs = r[f'first_downs_{homeaway}']\n",
    "            third_downs_raw = r[f'third_downs_{homeaway}']\n",
    "            fourth_downs_raw = r[f'fourth_downs_{homeaway}']\n",
    "            passing_yards = r[f'passing_yards_{homeaway}']\n",
    "            rushing_yards = r[f'rushing_yards_{homeaway}']\n",
    "            total_yards = r[f'total_yards_{homeaway}']\n",
    "            passing_yard_ratio = passing_yards / max(1, total_yards)\n",
    "            rushing_yard_ratio = rushing_yards / max(1, total_yards)\n",
    "            comp_att = r[f'comp_att_{homeaway}']\n",
    "            sacks_raw = r[f'sacks_{homeaway}']\n",
    "            sack_count = int(sacks_raw.split('-')[0])\n",
    "            sack_yards = int(sacks_raw.split('-')[1])\n",
    "            rushing_attempts = r[f'rushing_attempts_{homeaway}']\n",
    "            fumbles = r[f'fumbles_{homeaway}']\n",
    "            ints = r[f'int_{homeaway}']\n",
    "            turnovers = r[f'turnovers_{homeaway}']\n",
    "            penalties_raw = r[f'penalties_{homeaway}']\n",
    "            penalty_count = int(penalties_raw.split('-')[0])\n",
    "            penalty_yards = int(penalties_raw.split('-')[1])\n",
    "            redzone_raw = r[f'redzone_{homeaway}']\n",
    "            redzone_count = int(redzone_raw.split('-')[0])\n",
    "            redzone_yards = int(redzone_raw.split('-')[1])\n",
    "            drives = r[f'drives_{homeaway}']\n",
    "            def_st_td = r[f'def_st_td_{homeaway}']\n",
    "            possession = r[f'possession_{homeaway}']\n",
    "            score = int(r[f'score_{homeaway}'])\n",
    "            score_opponent = int(r[f'score_{awayhome}'])\n",
    "            wintieloss = 1 if score > score_opponent else (0 if score < score_opponent else 0.5)\n",
    "            third_down_conversions = 0 if int(third_downs_raw.split('-')[1]) == 0 else \\\n",
    "                int(third_downs_raw.split('-')[0]) / int(third_downs_raw.split('-')[1])\n",
    "                    # fixme (None rather than 0 is preferred but not handled correctly)\n",
    "            third_downs = int(third_downs_raw.split('-')[1])\n",
    "            fourth_down_conversions = 0 if int(fourth_downs_raw.split('-')[1]) == 0 else \\\n",
    "                int(fourth_downs_raw.split('-')[0]) / int(fourth_downs_raw.split('-')[1])\n",
    "                     # fixme (None rather than 0 is preferred but not handled correctly)\n",
    "            fourth_downs = int(fourth_downs_raw.split('-')[1])\n",
    "            rushing_to_passing = int(rushing_yards) / max(1, int(passing_yards))\n",
    "            comp = int(comp_att.split('-')[0])\n",
    "            att = int(comp_att.split('-')[1])\n",
    "            comp_att_ratio = comp / max(1, att)\n",
    "            elo = elo_dict[f'{team}|{date}']['elo-post']\n",
    "            qb_elo = elo_dict[f'{team}|{date}']['qb-elo-post']\n",
    "\n",
    "            espn_qbr_key = f'{team}|{date}'\n",
    "            if espn_qbr_key in espn_qbr_dict.keys():\n",
    "                espn_qbr = espn_qbr_dict[espn_qbr_key]\n",
    "                espn_qbr_missing = 0\n",
    "            else:\n",
    "                # print(f'something wrong with {espn_qbr_key}')\n",
    "                missing_qbr_count += 1\n",
    "                espn_qbr = 50    \n",
    "                espn_qbr_missing = 1\n",
    "\n",
    "            row = {\n",
    "                'date': date,\n",
    "                'team': team,\n",
    "                'opponent': opponent,\n",
    "                'rivalry': rivalry,\n",
    "                'home?': homeQ,\n",
    "                'first-downs': first_downs,\n",
    "                'third-downs': third_downs,\n",
    "                'third-down-conversion': third_down_conversions,\n",
    "                'fourth-downs': fourth_downs,\n",
    "                'fourth-down-conversion': fourth_down_conversions,\n",
    "                'passing-yards': passing_yards,\n",
    "                'rushing-yards': rushing_yards,\n",
    "                'total-yards': total_yards,\n",
    "                'rushing-to-passing': rushing_to_passing,\n",
    "                'passing-yard-ratio': passing_yard_ratio,\n",
    "                'rushing-yard-ratio': rushing_yard_ratio,\n",
    "                'elo': elo,\n",
    "                'qb-elo': qb_elo,\n",
    "                'espn-qbr': espn_qbr,\n",
    "                'espn-qbr-missing': espn_qbr_missing,\n",
    "                'comp': comp,\n",
    "                'att': att,\n",
    "                'comp-att': comp_att_ratio,\n",
    "                'sack_count': sack_count,\n",
    "                'sack_yards': sack_yards,\n",
    "                'rushing-attempts': rushing_attempts,\n",
    "                'fumbles': fumbles,\n",
    "                'int': ints,\n",
    "                'turnovers': turnovers,\n",
    "                'penalty_count': penalty_count,\n",
    "                'penalty_yards': penalty_yards,\n",
    "                'redzone_count': redzone_count,\n",
    "                'redzone_yards': redzone_yards,\n",
    "                'drives': drives,\n",
    "                'def-st-td': def_st_td,\n",
    "                'possession': possession,\n",
    "                'score': score,\n",
    "                'wintieloss': wintieloss,\n",
    "            }\n",
    "            if homeQ:\n",
    "                row_home = row\n",
    "            else:\n",
    "                row_away = row\n",
    "\n",
    "        # compute advantages, which is the ratio of a selection of numbers between the two teams\n",
    "\n",
    "        #advantages = [\n",
    "        #    'first-downs', 'third-down-conversion', 'fourth-down-conversion',\n",
    "        #    'passing-yards', 'rushing-yards', 'total-yards', 'elo', 'comp-att',\n",
    "        #    'sack_count', 'fum'\n",
    "        #             ]\n",
    "\n",
    "        rows.append(row_home)\n",
    "        rows.append(row_away)\n",
    "\n",
    "    missing_qbr_percent = missing_qbr_count / (2 * len(team_stat)) * 100\n",
    "    print(f'missing {missing_qbr_count} QBRs ({missing_qbr_percent:.2f}%)')\n",
    "    twohalves = pd.DataFrame(rows)\n",
    "    \n",
    "    twohalves_dict = dict(\n",
    "        [(f\"{e['team']}|{e['date']}\", e) for e in twohalves.to_dict(orient='records')])\n",
    "    \n",
    "    teams = list(team_dates_dict.keys())\n",
    "    for team in teams:\n",
    "        count = 0\n",
    "        team_dates = team_dates_dict[team]\n",
    "        for team_date in team_dates:\n",
    "            count += 1\n",
    "        print(f'{team} has played a total of {count} games')\n",
    "        \n",
    "if not definition_only:\n",
    "    Part_VIII()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280ef3ea",
   "metadata": {},
   "source": [
    "# Part IX -- Compute League Averages (Weekly)\n",
    "\n",
    "Operating with twohalves, it is easy to compute the averages. The following include a pretty robust infrastructure that allows me to compute all kinds of averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f3114ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_league_averages():\n",
    "    \n",
    "    league = team_stat['home'].unique()  # all teams\n",
    "    excluded_keys = ['date', 'team', 'opponent', 'rivalry', 'home?']\n",
    "    league_averages = {}\n",
    "    for index, r in tqdm(team_stat.iterrows(), total=len(team_stat), desc='Processing rows (IX)'):\n",
    "        date = r['date']\n",
    "        data = {}\n",
    "        for team in league:\n",
    "            key = f'{team}|{date}'\n",
    "            if key in twohalves_dict.keys():\n",
    "                entry = twohalves_dict[key]\n",
    "                for k, v in entry.items():\n",
    "                    if k not in excluded_keys:\n",
    "                        if k not in data.keys():\n",
    "                            data[k] = [v]\n",
    "                        else:\n",
    "                            data[k].append(v)\n",
    "                        \n",
    "        stat = {}\n",
    "        for k, v in data.items():\n",
    "            mean = statistics.mean(data[k])\n",
    "            std = statistics.stdev(data[k])\n",
    "            stat[k] = { 'mean': mean, 'std': std }\n",
    "                    \n",
    "        league_averages[date] = stat\n",
    "    \n",
    "    return league_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c999de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rolling_league_averages(data, window=8):\n",
    "    dates = list(data.keys())\n",
    "    rolling_league_averages = {}\n",
    "    for index in tqdm(range(len(dates)), desc='Processing rows (IX)'):\n",
    "        date = dates[index]\n",
    "        row = data[date]\n",
    "        current_date = parse_date(date)\n",
    "        sum = {}\n",
    "        for back_index in range(index, -1, -1):  # inclusive of current date\n",
    "            back_date = parse_date(dates[back_index])\n",
    "            if current_date['absolute'] - back_date['absolute'] > 366:\n",
    "                break\n",
    "            for k, v in data[back_date['date']].items():\n",
    "                if k in sum.keys():\n",
    "                    sum[k].append(v) \n",
    "                else:\n",
    "                    sum[k] = [v]\n",
    "        \n",
    "        \n",
    "        averages = {}\n",
    "        for k in sum.keys():\n",
    "            entries = sum[k]\n",
    "            sum_means = 0\n",
    "            sum_variances = 0\n",
    "            for e in entries:\n",
    "                sum_means += e['mean']\n",
    "                sum_variances += e['std'] * e['std']\n",
    "            overall_mean = sum_means / len(entries)\n",
    "            overall_std = math.sqrt(sum_variances / len(entries))\n",
    "                # this is an approximation, but not too far off\n",
    "            averages[k] = { 'mean': overall_mean, 'std': overall_std }\n",
    "            \n",
    "        rolling_league_averages[date] = averages\n",
    "        \n",
    "    return rolling_league_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "732af246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows (IX): 100%|████████████████| 4573/4573 [00:37<00:00, 122.52it/s]\n",
      "Processing rows (IX): 100%|██████████████████| 915/915 [00:01<00:00, 504.51it/s]\n"
     ]
    }
   ],
   "source": [
    "def Part_IX():\n",
    "    \n",
    "    global league_averages, rolling_league_averages\n",
    "    \n",
    "    league_averages = compute_league_averages()\n",
    "    rolling_league_averages = compute_rolling_league_averages(league_averages)\n",
    "    \n",
    "if not definition_only:\n",
    "    Part_IX()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b793acd3",
   "metadata": {},
   "source": [
    "# Part X -- Compute Averages\n",
    "\n",
    "Operating with twohalves, it is easy to compute the averages. The following include a pretty robust infrastructure that allows me to compute all kinds of averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68d6302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_averages(method, weekly_alpha, season_cliff, normalize):\n",
    "    # season so far, last season, last 365 days\n",
    "    \n",
    "    averageable_keys = list(next(iter(twohalves_dict.values())).keys())\n",
    "    excluded_keys = ['date', 'team', 'opponent', 'rivalry', 'home?']\n",
    "    averageable_keys = set([x for x in averageable_keys if x not in excluded_keys])\n",
    "    print(averageable_keys)    \n",
    "\n",
    "    if weekly_alpha == None:\n",
    "        weekly_alpha = 1\n",
    "    if season_cliff == None:\n",
    "        season_cliff = 1\n",
    "        \n",
    "    assert(method in ['this-season', 'last-season', 'last-365', 'historical', 'last-game'])\n",
    "    averages_dict = {}\n",
    "    teams = list(team_dates_dict.keys())\n",
    "    for team in tqdm(teams, desc='Processing rows (X)'):\n",
    "        team_dates = team_dates_dict[team]\n",
    "        for index in range(len(team_dates)):\n",
    "            current_date = parse_date(team_dates[index][0])\n",
    "            current_absolute = current_date['absolute']\n",
    "            current_key = f'{team}|{current_date[\"date\"]}'\n",
    "            current_entry = twohalves_dict[current_key]  # just basic info\n",
    "            current_head = { k: current_entry[k] for k in excluded_keys }\n",
    "            cumu_count = 0\n",
    "            cumu_sum = 0\n",
    "            cumu_weight = 0\n",
    "            cumu = None\n",
    "            for back_index in range(index - 1, -1, -1):\n",
    "                # going backward starting from index - 1, to 0 inclusive\n",
    "                back_date = parse_date(team_dates[back_index][0])\n",
    "                back_absolute = back_date['absolute']\n",
    "                if method == 'this-season':\n",
    "                    if back_date['season'] != current_date['season']:\n",
    "                        break\n",
    "                elif method == 'last-season':\n",
    "                    if back_date['season'] == current_date['season']:\n",
    "                        continue  # skip this season\n",
    "                    elif back_date['season'] < current_date['season'] - 1:\n",
    "                        break\n",
    "                elif method == 'last-365':\n",
    "                    if current_date['absolute'] - back_date['absolute'] > 366:  # generous\n",
    "                        break\n",
    "                elif method == 'historical':\n",
    "                    ()  # okay\n",
    "                elif method == 'last-game':  # take only the last game\n",
    "                    if back_index != index - 1:\n",
    "                        break\n",
    "                else:\n",
    "                    assert(False)  # unknown method\n",
    "\n",
    "                season_adjustment = season_cliff ** (current_date['season'] - back_date['season'])\n",
    "                    \n",
    "                delta_week = (current_date['absolute'] - back_date['absolute']) / 7\n",
    "                weight = (weekly_alpha ** delta_week) * season_adjustment\n",
    "                back_key = f'{team}|{back_date[\"date\"]}'\n",
    "                back_entry = twohalves_dict[back_key]\n",
    "                \n",
    "                if normalize:\n",
    "                    mu_sigma = rolling_league_averages[back_date['date']]\n",
    "                    mu = { k: v['mean'] for k, v in mu_sigma.items() }\n",
    "                    sigma = { k: v['std'] for k, v in mu_sigma.items() }\n",
    "                    back_entry = {\n",
    "                        k: (v - mu[k]) / max(1e-9, sigma[k]) if k in mu_sigma.keys() else v\n",
    "                            for k, v in back_entry.items()\n",
    "                    }\n",
    "                \n",
    "                if cumu_count == 0:\n",
    "                    cumu = { k: weight * back_entry[k] for k in averageable_keys }\n",
    "                else:\n",
    "                    cumu = { k: cumu[k] + weight * back_entry[k] for k in averageable_keys }\n",
    "                cumu_count += 1\n",
    "                cumu_weight += weight\n",
    "            if cumu_weight > 0:\n",
    "                averages = { k: cumu[k] / cumu_weight for k in cumu }\n",
    "            else:\n",
    "                averages = { k: 0 for k in averageable_keys }\n",
    "                                \n",
    "            current_tail = { k: averages[k] for k in averageable_keys }\n",
    "            averages_dict[current_key] = { **current_head, **current_tail }\n",
    "                # this is to preserve the order of the keys for ease of debugging\n",
    "            \n",
    "    return averages_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a4021f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows (X):  12%|██▉                    | 4/32 [00:00<00:00, 39.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score', 'rushing-yard-ratio', 'redzone_yards', 'rushing-to-passing', 'att', 'sack_count', 'drives', 'elo', 'possession', 'passing-yards', 'fourth-down-conversion', 'third-down-conversion', 'redzone_count', 'comp-att', 'rushing-yards', 'def-st-td', 'sack_yards', 'fumbles', 'comp', 'rushing-attempts', 'third-downs', 'wintieloss', 'total-yards', 'passing-yard-ratio', 'espn-qbr', 'penalty_count', 'first-downs', 'fourth-downs', 'int', 'espn-qbr-missing', 'penalty_yards', 'turnovers', 'qb-elo'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows (X): 100%|██████████████████████| 32/32 [00:00<00:00, 39.48it/s]\n",
      "Processing rows (X):   6%|█▍                     | 2/32 [00:00<00:02, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score', 'rushing-yard-ratio', 'redzone_yards', 'rushing-to-passing', 'att', 'sack_count', 'drives', 'elo', 'possession', 'passing-yards', 'fourth-down-conversion', 'third-down-conversion', 'redzone_count', 'comp-att', 'rushing-yards', 'def-st-td', 'sack_yards', 'fumbles', 'comp', 'rushing-attempts', 'third-downs', 'wintieloss', 'total-yards', 'passing-yard-ratio', 'espn-qbr', 'penalty_count', 'first-downs', 'fourth-downs', 'int', 'espn-qbr-missing', 'penalty_yards', 'turnovers', 'qb-elo'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows (X): 100%|██████████████████████| 32/32 [00:02<00:00, 11.82it/s]\n",
      "Processing rows (X):   0%|                               | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score', 'rushing-yard-ratio', 'redzone_yards', 'rushing-to-passing', 'att', 'sack_count', 'drives', 'elo', 'possession', 'passing-yards', 'fourth-down-conversion', 'third-down-conversion', 'redzone_count', 'comp-att', 'rushing-yards', 'def-st-td', 'sack_yards', 'fumbles', 'comp', 'rushing-attempts', 'third-downs', 'wintieloss', 'total-yards', 'passing-yard-ratio', 'espn-qbr', 'penalty_count', 'first-downs', 'fourth-downs', 'int', 'espn-qbr-missing', 'penalty_yards', 'turnovers', 'qb-elo'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows (X): 100%|██████████████████████| 32/32 [00:06<00:00,  5.17it/s]\n"
     ]
    }
   ],
   "source": [
    "def Part_X():\n",
    "\n",
    "    global this_season, last_season, historical, last_365, last_game\n",
    "    \n",
    "    weekly_alpha = GLOBAL['weekly_alpha']\n",
    "    season_cliff = GLOBAL['season_cliff']\n",
    "    normalize = GLOBAL['normalize']\n",
    "    last_game = compute_averages('last-game',\n",
    "        weekly_alpha=weekly_alpha,\n",
    "        season_cliff=season_cliff, normalize=normalize)\n",
    "    this_season = compute_averages('this-season',\n",
    "        weekly_alpha=weekly_alpha,\n",
    "        season_cliff=season_cliff, normalize=normalize)\n",
    "    last_season = compute_averages('last-season',\n",
    "        weekly_alpha=weekly_alpha,\n",
    "        season_cliff=season_cliff, normalize=normalize)\n",
    "\n",
    "if not definition_only:\n",
    "    Part_X()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c2a09",
   "metadata": {},
   "source": [
    "# Part XI -- Final Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "923f159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table(averages_collection):\n",
    "    \n",
    "    excluded_keys = ['date', 'team', 'opponent', 'rivalry', 'home?']\n",
    "    final = {}\n",
    "    for index, r in tqdm(team_stat.iterrows(), total=len(team_stat), desc='Processing rows (XI)'):\n",
    "        date = r['date']\n",
    "        home = r['home']\n",
    "        away = r['away']\n",
    "        home_key = f'{home}|{date}'\n",
    "        away_key = f'{away}|{date}'\n",
    "        label = 1 if int(r['score_home']) >= int(r['score_away']) else 0\n",
    "            # label is 1 if the home team win or tie, or 0 otherwise\n",
    "        merged = {\n",
    "            'date': date,\n",
    "            'home': home,\n",
    "            'away': away,\n",
    "            'rivalry': f'{home}-{away}',\n",
    "            'label': label\n",
    "        }\n",
    "        final_key = f'{home}-{away}|{date}'\n",
    "        for (averages, name) in averages_collection:\n",
    "            home_suffix = f'-home-{name}'\n",
    "            away_suffix = f'-away-{name}'\n",
    "            assert(home_key in averages and away_key in averages)\n",
    "            home_entry = averages[home_key]\n",
    "            home_entry = { k + home_suffix: v for k, v in home_entry.items() if k not in excluded_keys}\n",
    "            away_entry = averages[away_key]\n",
    "            away_entry = { k + away_suffix: v for k, v in away_entry.items() if k not in excluded_keys }\n",
    "            \n",
    "            merged.update(home_entry)\n",
    "            merged.update(away_entry)\n",
    "\n",
    "        final[final_key] = merged\n",
    "            \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8be1660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows (XI): 100%|███████████████| 4573/4573 [00:01<00:00, 3552.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exported to tabular-095-050-norm.csv\n"
     ]
    }
   ],
   "source": [
    "def Part_XI():\n",
    "    \n",
    "    global tabular_dict, tabular_df\n",
    "    \n",
    "    averages_collection = [  # will turn this into features\n",
    "        (last_game, 'last'),\n",
    "        (this_season, 'season'),\n",
    "        (last_season, 'last-season'),\n",
    "    ]\n",
    "    tabular_dict = make_table(averages_collection)    \n",
    "    tabular_df = pd.DataFrame([v for k, v in tabular_dict.items()])\n",
    "    tabular_df.to_csv(GLOBAL['filename'])\n",
    "    print(f\"exported to {GLOBAL['filename']}\")\n",
    "    \n",
    "if not definition_only:\n",
    "    Part_XI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0709ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Part_All():\n",
    "    parts = [\n",
    "        Part_I,\n",
    "        Part_II,\n",
    "        Part_III,\n",
    "        Part_IV,\n",
    "        Part_V,\n",
    "        Part_VI,\n",
    "        Part_VII,\n",
    "        Part_VIII,\n",
    "        Part_IX,\n",
    "        Part_X,\n",
    "        Part_XI,\n",
    "    ]\n",
    "    for part in parts:\n",
    "        part()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d05dc91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part_All()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
